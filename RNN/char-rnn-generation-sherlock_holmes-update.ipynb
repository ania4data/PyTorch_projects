{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/eBRPvWB.png)\n",
    "\n",
    "# Practical PyTorch: Generating Shakespeare with a Character-Level RNN\n",
    "\n",
    "[In the RNN classification tutorial](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) we used a RNN to classify text one character at a time. This time we'll generate text one character at a time.\n",
    "\n",
    "```\n",
    "> python generate.py -n 500\n",
    "\n",
    "PAOLTREDN:\n",
    "Let, yil exter shis owrach we so sain, fleas,\n",
    "Be wast the shall deas, puty sonse my sheete.\n",
    "\n",
    "BAUFIO:\n",
    "Sirh carrow out with the knonuot my comest sifard queences\n",
    "O all a man unterd.\n",
    "\n",
    "PROMENSJO:\n",
    "Ay, I to Heron, I sack, againous; bepear, Butch,\n",
    "An as shalp will of that seal think.\n",
    "\n",
    "NUKINUS:\n",
    "And house it to thee word off hee:\n",
    "And thou charrota the son hange of that shall denthand\n",
    "For the say hor you are of I folles muth me?\n",
    "```\n",
    "\n",
    "This one might make you question the series title &mdash; \"is that really practical?\" However, these sorts of generative models form the basis of machine translation, image captioning, question answering and more. See the [Sequence to Sequence Translation tutorial](https://github.com/spro/practical-pytorch/blob/master/seq2seq-translation/seq2seq-translation.ipynb) for more on that topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommended Reading\n",
    "\n",
    "I assume you have at least installed PyTorch, know Python, and understand Tensors:\n",
    "\n",
    "* http://pytorch.org/ For installation instructions\n",
    "* [Deep Learning with PyTorch: A 60-minute Blitz](https://github.com/pytorch/tutorials/blob/master/Deep%20Learning%20with%20PyTorch.ipynb) to get started with PyTorch in general\n",
    "* [jcjohnson's PyTorch examples](https://github.com/jcjohnson/pytorch-examples) for an in depth overview\n",
    "* [Introduction to PyTorch for former Torchies](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb) if you are former Lua Torch user\n",
    "\n",
    "It would also be useful to know about RNNs and how they work:\n",
    "\n",
    "* [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) shows a bunch of real life examples\n",
    "* [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) is about LSTMs specifically but also informative about RNNs in general\n",
    "\n",
    "Also see these related tutorials from the series:\n",
    "\n",
    "* [Classifying Names with a Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/char-rnn-classification/char-rnn-classification.ipynb) uses an RNN for classification\n",
    "* [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb) builds on this model to add a category as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "The file we are using is a plain text file. We turn any potential unicode characters into plain ASCII by using the `unidecode` package (which you can install via `pip` or `conda`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n",
      "\u000b",
      "\f",
      "\n",
      "file_len = 2046803\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "\n",
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "print(n_characters)\n",
    "print(all_characters)\n",
    "file = unidecode.unidecode(open('sherlock_holmes_all.txt').read())  #unicode to ascii\n",
    "file_len = len(file)\n",
    "print('file_len =', file_len)  #basically nuumber of characters\n",
    "#print(file) #print whole file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make inputs out of this big string of data, we will be splitting it into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " of crime, in its legal sense, at all. The\n",
      " small matter in which I endeavoured to help the King of Bohemia, the\n",
      " singular experience of Miss Mary Sutherland, the problem connected\n",
      " with the man with the twisted lip, and the incident of the noble\n",
      " bachelor, were all matters which are outside the pale of the law. But\n",
      " in avoiding the sensational, I fear that you may have bordered on the\n",
      " trivial.\"\n",
      "\n",
      " \"The end may have been so,\" I answered, \"but the methods I hold to\n",
      " have been novel and of interest\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 500\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)  #start index\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())  #give a 500 length sentence randomly each time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "\n",
    "This model will take as input the character for step $t_{-1}$ and is expected to output the next character $t$. There are three layers - one linear layer that encodes the input character into an internal state, one GRU layer (which may itself have multiple layers) that operates on that internal state and a hidden state, and a decoder layer that outputs the probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs and Targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each chunk will be turned into a tensor, specifically a `LongTensor` (used for integer values), by looping through the characters of the string and looking up the index of each character in `all_characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 10,  11,  12,  39,  40,  41])\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can assemble a pair of input and target tensors for training, from a random chunk. The input will be all characters *up to the last*, and the target will be all characters *from the first*. So if our chunk is \"abc\" the input will correspond to \"ab\" while the target is \"bc\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 94,  32,  18,  29,  17,  94,  10,  94,  27,  14,  31,  24,\n",
       "          21,  31,  14,  27,  94,  18,  23,  15,  21,  18,  12,  29,\n",
       "          94,  28,  24,  94,  13,  14,  10,  13,  21,  34,  94,  10,\n",
       "          94,  32,  24,  30,  23,  13,  75,  96,  94,  36,  16,  10,\n",
       "          18,  23,  73,  94,  51,  10,  27,  20,  94,  47,  10,  23,\n",
       "          14,  94,  18,  28,  94,  10,  94,  15,  27,  14,  26,  30,\n",
       "          14,  23,  29,  14,  13,  94,  29,  17,  24,  27,  24,  30,\n",
       "          16,  17,  15,  10,  27,  14,  73,  94,  10,  23,  13,  94,\n",
       "          29,  17,  14,  27,  14,  94,  18,  28,  94,  10,  96,  94,\n",
       "          12,  10,  11,  74,  28,  29,  10,  23,  13,  94,  32,  18,\n",
       "          29,  17,  18,  23,  94,  10,  94,  17,  30,  23,  13,  27,\n",
       "          14,  13,  94,  34,  10,  27,  13,  28,  94,  24,  15,  94,\n",
       "          29,  17,  14,  94,  17,  24,  30,  28,  14,  75,  94,  49,\n",
       "          24,  94,  24,  23,  14,  94,  17,  10,  13,  94,  17,  14,\n",
       "          10,  27,  13,  94,  10,  96,  94,  28,  17,  24,  29,  75,\n",
       "          94,  36,  23,  13,  94,  34,  14,  29,  94,  29,  17,  14,\n",
       "          27,  14,  94,  32,  10,  28,  94,  29,  17,  14,  94,  13,\n",
       "          14,  10,  13,  94,  22,  10,  23,  73,  94,  10,  23,  13,\n",
       "          94,  29,  17,  14,  27,  14,  94,  29,  17,  14,  94,  27,\n",
       "          14,  31,  24,  21,  31,  14,  27,  94,  11,  30,  21,  21,\n",
       "          14,  29,  73,  96,  94,  32,  17,  18,  12,  17,  94,  17,\n",
       "          10,  13,  94,  22,  30,  28,  17,  27,  24,  24,  22,  14,\n",
       "          13,  94,  24,  30,  29,  73,  94,  10,  28,  94,  28,  24,\n",
       "          15,  29,  74,  23,  24,  28,  14,  13,  94,  11,  30,  21,\n",
       "          21,  14,  29,  28,  94,  32,  18,  21,  21,  73,  94,  10,\n",
       "          23,  13,  94,  28,  24,  96,  94,  18,  23,  15,  21,  18,\n",
       "          12,  29,  14,  13,  94,  10,  94,  32,  24,  30,  23,  13,\n",
       "          94,  32,  17,  18,  12,  17,  94,  22,  30,  28,  29,  94,\n",
       "          17,  10,  31,  14,  94,  12,  10,  30,  28,  14,  13,  94,\n",
       "          18,  23,  28,  29,  10,  23,  29,  10,  23,  14,  24,  30,\n",
       "          28,  94,  13,  14,  10,  29,  17,  75,  94,  54,  30,  12,\n",
       "          17,  96,  94,  32,  14,  27,  14,  94,  29,  17,  14,  94,\n",
       "          12,  18,  27,  12,  30,  22,  28,  29,  10,  23,  12,  14,\n",
       "          28,  94,  24,  15,  94,  29,  17,  14,  94,  51,  10,  27,\n",
       "          20,  94,  47,  10,  23,  14,  94,  48,  34,  28,  29,  14,\n",
       "          27,  34,  73,  94,  32,  17,  18,  12,  17,  94,  32,  14,\n",
       "          27,  14,  94,  15,  30,  27,  29,  17,  14,  27,  96,  94,\n",
       "          12,  24,  22,  25,  21,  18,  12,  10,  29,  14,  13,  94,\n",
       "          11,  34,  94,  14,  23,  29,  18,  27,  14,  94,  10,  11,\n",
       "          28,  14,  23,  12,  14,  94,  24,  15,  94,  22,  24,  29,\n",
       "          18,  31,  14,  73,  94,  28,  18,  23,  12,  14,  73,  94,\n",
       "          10,  28,  94,  44,  94,  17,  10,  31]),\n",
       " tensor([ 32,  18,  29,  17,  94,  10,  94,  27,  14,  31,  24,  21,\n",
       "          31,  14,  27,  94,  18,  23,  15,  21,  18,  12,  29,  94,\n",
       "          28,  24,  94,  13,  14,  10,  13,  21,  34,  94,  10,  94,\n",
       "          32,  24,  30,  23,  13,  75,  96,  94,  36,  16,  10,  18,\n",
       "          23,  73,  94,  51,  10,  27,  20,  94,  47,  10,  23,  14,\n",
       "          94,  18,  28,  94,  10,  94,  15,  27,  14,  26,  30,  14,\n",
       "          23,  29,  14,  13,  94,  29,  17,  24,  27,  24,  30,  16,\n",
       "          17,  15,  10,  27,  14,  73,  94,  10,  23,  13,  94,  29,\n",
       "          17,  14,  27,  14,  94,  18,  28,  94,  10,  96,  94,  12,\n",
       "          10,  11,  74,  28,  29,  10,  23,  13,  94,  32,  18,  29,\n",
       "          17,  18,  23,  94,  10,  94,  17,  30,  23,  13,  27,  14,\n",
       "          13,  94,  34,  10,  27,  13,  28,  94,  24,  15,  94,  29,\n",
       "          17,  14,  94,  17,  24,  30,  28,  14,  75,  94,  49,  24,\n",
       "          94,  24,  23,  14,  94,  17,  10,  13,  94,  17,  14,  10,\n",
       "          27,  13,  94,  10,  96,  94,  28,  17,  24,  29,  75,  94,\n",
       "          36,  23,  13,  94,  34,  14,  29,  94,  29,  17,  14,  27,\n",
       "          14,  94,  32,  10,  28,  94,  29,  17,  14,  94,  13,  14,\n",
       "          10,  13,  94,  22,  10,  23,  73,  94,  10,  23,  13,  94,\n",
       "          29,  17,  14,  27,  14,  94,  29,  17,  14,  94,  27,  14,\n",
       "          31,  24,  21,  31,  14,  27,  94,  11,  30,  21,  21,  14,\n",
       "          29,  73,  96,  94,  32,  17,  18,  12,  17,  94,  17,  10,\n",
       "          13,  94,  22,  30,  28,  17,  27,  24,  24,  22,  14,  13,\n",
       "          94,  24,  30,  29,  73,  94,  10,  28,  94,  28,  24,  15,\n",
       "          29,  74,  23,  24,  28,  14,  13,  94,  11,  30,  21,  21,\n",
       "          14,  29,  28,  94,  32,  18,  21,  21,  73,  94,  10,  23,\n",
       "          13,  94,  28,  24,  96,  94,  18,  23,  15,  21,  18,  12,\n",
       "          29,  14,  13,  94,  10,  94,  32,  24,  30,  23,  13,  94,\n",
       "          32,  17,  18,  12,  17,  94,  22,  30,  28,  29,  94,  17,\n",
       "          10,  31,  14,  94,  12,  10,  30,  28,  14,  13,  94,  18,\n",
       "          23,  28,  29,  10,  23,  29,  10,  23,  14,  24,  30,  28,\n",
       "          94,  13,  14,  10,  29,  17,  75,  94,  54,  30,  12,  17,\n",
       "          96,  94,  32,  14,  27,  14,  94,  29,  17,  14,  94,  12,\n",
       "          18,  27,  12,  30,  22,  28,  29,  10,  23,  12,  14,  28,\n",
       "          94,  24,  15,  94,  29,  17,  14,  94,  51,  10,  27,  20,\n",
       "          94,  47,  10,  23,  14,  94,  48,  34,  28,  29,  14,  27,\n",
       "          34,  73,  94,  32,  17,  18,  12,  17,  94,  32,  14,  27,\n",
       "          14,  94,  15,  30,  27,  29,  17,  14,  27,  96,  94,  12,\n",
       "          24,  22,  25,  21,  18,  12,  10,  29,  14,  13,  94,  11,\n",
       "          34,  94,  14,  23,  29,  18,  27,  14,  94,  10,  11,  28,\n",
       "          14,  23,  12,  14,  94,  24,  15,  94,  22,  24,  29,  18,\n",
       "          31,  14,  73,  94,  28,  18,  23,  12,  14,  73,  94,  10,\n",
       "          28,  94,  44,  94,  17,  10,  31,  14]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_training_set():    \n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "   # target=torch.LongTensor([target])\n",
    "    return inp, target\n",
    "\n",
    "random_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating\n",
    "\n",
    "To evaluate the network we will feed one character at a time, use the outputs of the network as a probability distribution for the next character, and repeat. To start generation we pass a priming string to start building up the hidden state, from which we then generate one character at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper to print the amount of time passed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        #output = output.unsqueeze(0)\n",
    "        #target[c]=torch.LongTensor([target[c]])\n",
    "        target_=torch.tensor([target[c]])\n",
    "        loss += criterion(output, target_)\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "   # print(loss)\n",
    "\n",
    "    return loss.data / chunk_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the training parameters, instantiate the model, and start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13m 0s (1000 10%) 1.7089]\n",
      "How, to Holmes been have been seemmor\n",
      " gives said of the this iden this and a ta\n",
      " little and a for the Colonel my deep said with his had noth\n",
      " mage to me come inchfect he courned a battorate now with in \n",
      "\n",
      "Watinatised you\n",
      " had not ced a so panger\n",
      " the commes case own that was had day He has this the this feame was in his sumban expatuelably\n",
      " amed for you me. He are clee that be he to\n",
      " mind of this most in \n",
      "\n",
      "[24m 43s (2000 20%) 1.5853]\n",
      "How is enought for\n",
      " spleached in the worrid roominar. Well and know you worlut on that that the\n",
      " comptmate. And you wour return the morate more was and featanly found foot be been much\n",
      " had bunding and  \n",
      "\n",
      "Was the is feele was to the papeal. Of the save to the spoy was surbable easter set\n",
      " her of profoincence of the cascar, leave if the order. I was\n",
      " about for which with the morrow lad to be was tone our  \n",
      "\n",
      "[36m 39s (3000 30%) 1.5261]\n",
      "However mime in the\n",
      " riffisue curibock out to see his respeint of astonly of the sion our appeared\n",
      " out you have the soull centing that I have not returning\n",
      " our housell carred that issend to so. The op \n",
      "\n",
      "Wat, and in all of marriage.\n",
      " On laughing you certay everetice may table very of interest me.  Sherloponising who have still it is may in such\n",
      " Holmes done of myserfusuince of But his day pristand. \"The \n",
      "\n",
      "[48m 40s (4000 40%) 1.4629]\n",
      "Holmes would a\n",
      " profor tturned of not have been been his the impanatial commandly\n",
      " heard with nothing upon you would no fold was ake all the\n",
      " roser, and thillmand, my sittenly have for's part case of af \n",
      "\n",
      "Wak fellow within the just, and\n",
      " the much last and head here apt, and I had been to grantly withed had\n",
      " bearry still of inton to the cot her window, not stally, and it is that\n",
      " then waiting in ent Cuces \n",
      "\n",
      "[61m 15s (5000 50%) 1.5585]\n",
      "Holmes?\"\n",
      "\n",
      " \"On my life with the on'twentisions at so, thee carriages and of his my first.\n",
      " Holmes, for Holmes, but these advermina two story clear and was\n",
      " found the doubt with the excised pressed not w \n",
      "\n",
      "Wates of the hands as was\n",
      " blue in Prensing-seen without his round. He had life absolvesso\n",
      " his haggired as his countrys, however with his feamined\n",
      " in Hove Flanger. Then you walked very down a here the \n",
      "\n",
      "[73m 40s (6000 60%) 1.3338]\n",
      "How or the hearl\n",
      " of this off, with the a's are in his hand some pokes with a carice as a very hardly,\n",
      " stative Passight of the lid, farancy to him. A meant to the straigh,\n",
      " and this life where hundred  \n",
      "\n",
      "Wable. You have the\n",
      " harled that you cercomed it, and what he had a found me. He the\n",
      " professions with me in the marks of the for a quity wordhs so that so\n",
      " to the mince, the morning that some of a smoo \n",
      "\n",
      "[86m 31s (7000 70%) 1.4991]\n",
      "Holming, not ponected\n",
      " with a conderent which hand you cried to this carge fir. Hosment them? It was the long\n",
      " that way one flonk inclays that it that I was naince enought and confally and\n",
      " pair down, a \n",
      "\n",
      "Wach of you can deen. Then\n",
      " the hall to came more clace, leaned at the matter. Frusteration, which\n",
      " Meady nevagrria the expling expeons me again in could of a crime word and he\n",
      " shull thinked, and he be \n",
      "\n",
      "[98m 48s (8000 80%) 1.4118]\n",
      "Holmes of chiligy that\n",
      " I had should not did do corrow drugging-retrund down and such into the money\n",
      " and my laid in the dread station. I wateryed faces of some and to the\n",
      " pocket in his wring into way  \n",
      "\n",
      "Wand her loss to two it\n",
      " within of met his for this ford of intition. He had do never me and\n",
      " in of to the postia his more the want to ating the tlad which\n",
      " see which shat which should walk with this it \n",
      "\n",
      "[111m 6s (9000 90%) 1.7075]\n",
      "Holmes say had\n",
      " anyone of Parrection, not you do your marks conculd his night,\n",
      " it was resurs doen of the proceers to made. On a way in your insarly up officulored. Pond see\n",
      " you already examined you di \n",
      "\n",
      "Was. The some in ority of the\n",
      " kemed and or your own case this way inciding seances. He man shall\n",
      " ham those, And crut and so made a last of box some inquire an old did that or\n",
      " wish, as I can had for t \n",
      "\n",
      "[123m 52s (10000 100%) 1.4769]\n",
      "Holmes, but I wenk\n",
      " we exais change, and it as asqarminged in one.\"\n",
      "\n",
      " \"There had really, as havened in his busion, and of my grounne\n",
      " or her entery. You asked heose was it is a gese. Thing more\n",
      " his man \n",
      "\n",
      "Want, yetpisten to my staype and eacty\n",
      " bunzaggerous, and it the percitity passried aring at the statema a some a\n",
      " hands and a life your neles. Then we sametle from the known that\n",
      " parcurent of his call \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10000\n",
    "print_every = 1000\n",
    "plot_every = 1000\n",
    "hidden_size = n_characters\n",
    "n_layers = 3\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    xx,yy=random_training_set()\n",
    "    #print(xx,yy)\n",
    "    loss = train(xx,yy)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        decoder.eval()\n",
    "        print(evaluate('Ho', 200), '\\n')\n",
    "        print(evaluate('Wa', 200), '\\n')\n",
    "        decoder.train()\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Training Losses\n",
    "\n",
    "Plotting the historical loss from all_losses shows the network learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x263379baf60>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating at different \"temperatures\"\n",
    "\n",
    "In the `evaluate` function above, every time a prediction is made the outputs are divided by the \"temperature\" argument passed. Using a higher number makes all actions more equally likely, and thus gives us \"more random\" outputs. Using a lower value (less than 1) makes high probabilities contribute more. As we turn the temperature towards zero we are choosing only the most likely outputs.\n",
    "\n",
    "We can see the effects of this by adjusting the `temperature` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor Moriarty\n",
      " and all entered from the sear a singure at the good of the state\n",
      " address of his carriage not of the pather which he drawger in the whole.\n",
      "\n",
      " \"'You convern the with the sitte of a floor and my draw. \n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Professor Moriarty', 200, temperature=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmend him? Condrss,' shen\n",
      " fince throunds. Maside that tWoughly.\"\n",
      "\n",
      " A jin ttoce ceracfasion Gook.\"\n",
      "\n",
      " \"On you ardished cleagage that my Broke then. Excot was\n",
      " though. He was only load him votbers Squabst\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=1.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes.  He was sugk\n",
      " you have extents?\"\n",
      "\n",
      " \"Yar. Now, With they had so Torner, and not into then my\n",
      " kaltia Rost of real into there descridge, with no, here?\" Nurt for\n",
      " sharm to this atterment for her.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes. Now, glorious\n",
      " hif her whethere had a roughing his well and a lamberniscrister came wife,\n",
      " but, and led coudrey content upon a caskipe. You outent of the ensidectaress\n",
      " threas clue on these of out\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes his chore, and he, which his not, and\n",
      " still be the assuals the inspector for the elare which he met a speceme of pains and a\n",
      " other mapable gain of the grassores, it.\n",
      "\n",
      " \"You was the bore?\"\n",
      "\n",
      " \"You \n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes, we quite world on the one\n",
      " the week and that dead the good, have the whower the man and side of his conside\n",
      " of conside of the pharise at us in an nention. He are do the last\n",
      " has say and so house\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes who seen an and be a\n",
      " constrange.\"\n",
      "\n",
      " \"There force out and the confess a shoulder?' asked Holmes, and I have\n",
      " she starting it to suspect the persham, the will go before an expector\n",
      " and him. The onl\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes at the man, and\n",
      " the same of the man, with the conse which he had been in his should purportance which\n",
      " was a looked of the should have to the kept the said at his entered starter and\n",
      " the man of t\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower temperatures are less varied, choosing only the more probable outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes and a state of the same\n",
      " and a grass of the sight and the past of the second of the man and the side\n",
      " and a street the short which he was a conside and he was a statest of the\n",
      " state were and a sta\n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher temperatures more varied, choosing less probable outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holmes and a state of the shall and a\n",
      " state of the shall present of the shall present of the second of the shall\n",
      " starting that the shall of the shall of the state of the shall present and the shall and \n"
     ]
    }
   ],
   "source": [
    "print(evaluate('Holm', 200, temperature=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercises\n",
    "\n",
    "* Train with your own dataset, e.g.\n",
    "    * Text from another author\n",
    "    * Blog posts\n",
    "    * Code\n",
    "* Increase number of layers and network size to get better results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next**: [Generating Names with a Conditional Character-Level RNN](https://github.com/spro/practical-pytorch/blob/master/conditional-char-rnn/conditional-char-rnn.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
