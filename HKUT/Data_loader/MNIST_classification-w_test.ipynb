{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets,transforms,utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset=datasets.MNIST('MNIST/',train=True,transform=transform,download=True)\n",
    "train_loader=DataLoader(trainset,batch_size=64,shuffle=True)\n",
    "\n",
    "testset=datasets.MNIST('MNIST/',train=False,transform=transform,download=True)\n",
    "test_loader=DataLoader(testset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f7d2db2be0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image,label=next(iter(train_loader))\n",
    "print(image.size())\n",
    "print(label.size())\n",
    "plt.imshow(image[0][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  7,  8,  4,  1,  8,  1,  2,  8,  5,  0,  2,  8,  2,\n",
       "         0,  3,  3,  8,  1,  1,  9,  9,  1,  5,  5,  5,  3,  5,\n",
       "         4,  8,  5,  1,  5,  4,  1,  6,  5,  9,  8,  8,  8,  1,\n",
       "         5,  1,  5,  7,  6,  7,  6,  1,  8,  6,  7,  3,  7,  4,\n",
       "         6,  6,  4,  1,  3,  0,  2,  7])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.fc1=torch.nn.Linear(784,600)\n",
    "        self.dropout1=torch.nn.Dropout(p=0.2)\n",
    "        self.fc2=torch.nn.Linear(600,400)\n",
    "        self.fc3=torch.nn.Linear(400,200)\n",
    "        self.dropout2=torch.nn.Dropout(p=0.2)\n",
    "        self.fc4=torch.nn.Linear(200,100)\n",
    "        self.fc5=torch.nn.Linear(100,10)\n",
    "        #self.sigmoid=torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=x.view(-1,784)  #flatten in forward instead of train\n",
    "        out1=F.relu(self.fc1(x))\n",
    "        out1=self.dropout1(out1)\n",
    "        out2=F.relu(self.fc2(out1))\n",
    "        out2=self.dropout2(out2)\n",
    "        out3=F.relu(self.fc3(out2))\n",
    "        out4=F.relu(self.fc4(out3))   #sof max at end, or sigmoid all the way did not work out\n",
    "        #y_pred=F.softmax(out4,dim=1)   #if don't need probability as out put not necessary output4 is batch_size*10\n",
    "        y_pred=F.relu(self.fc5(out4))\n",
    "        return y_pred\n",
    "\n",
    "model=Network()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "criterion=torch.nn.CrossEntropyLoss()  #if increase the lr to 0.1, it kicks to local min and stays\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)  #had to change from SGD to Adam but later noy much difference\n",
    "lr_scheduler_=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "#lr_scheduler_=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "epoch 1 / 10 running_loss: 0.029979440211318435 Accuracy 34.21875\n",
      "epoch 1 / 10 running_loss: 0.02092610101797618 Accuracy 54.859375\n",
      "epoch 1 / 10 running_loss: 0.016596486933606987 Accuracy 64.2109375\n",
      "epoch 1 / 10 running_loss: 0.014219481420295778 Accuracy 69.2109375\n",
      "epoch 2 / 10 running_loss: 0.01271852817975279 Accuracy 72.26113056528264\n",
      "epoch 2 / 10 running_loss: 0.011597638621517907 Accuracy 74.51933097123802\n",
      "epoch 2 / 10 running_loss: 0.01078016967447784 Accuracy 76.16559485530547\n",
      "epoch 2 / 10 running_loss: 0.01014899551517919 Accuracy 77.42458580806502\n",
      "epoch 2 / 10 running_loss: 0.009644403651555434 Accuracy 78.42456237843845\n",
      "epoch 3 / 10 running_loss: 0.009089413476802023 Accuracy 79.66326913456729\n",
      "epoch 3 / 10 running_loss: 0.008407436779622742 Accuracy 81.22584129149614\n",
      "epoch 3 / 10 running_loss: 0.007834599041750368 Accuracy 82.53829720716965\n",
      "epoch 3 / 10 running_loss: 0.007356542650069542 Accuracy 83.65236629472874\n",
      "epoch 3 / 10 running_loss: 0.006945613535225292 Accuracy 84.60555108967489\n",
      "epoch 4 / 10 running_loss: 0.006567454586887458 Accuracy 85.47138152409538\n",
      "epoch 4 / 10 running_loss: 0.006228637932906809 Accuracy 86.24892527747382\n",
      "epoch 4 / 10 running_loss: 0.005931332016836749 Accuracy 86.92253935559806\n",
      "epoch 4 / 10 running_loss: 0.005668516152589344 Accuracy 87.51736834792274\n",
      "epoch 5 / 10 running_loss: 0.005425479437574326 Accuracy 88.06896721958925\n",
      "epoch 5 / 10 running_loss: 0.005197098507452047 Accuracy 88.58218171585793\n",
      "epoch 5 / 10 running_loss: 0.0049913500802590514 Accuracy 89.04277334444974\n",
      "epoch 5 / 10 running_loss: 0.004811080496761512 Accuracy 89.45152626193725\n",
      "epoch 5 / 10 running_loss: 0.0046438334736873775 Accuracy 89.8311765985211\n",
      "epoch 6 / 10 running_loss: 0.00448447715370425 Accuracy 90.18857477853048\n",
      "epoch 6 / 10 running_loss: 0.004334095635894646 Accuracy 90.52088544272137\n",
      "epoch 6 / 10 running_loss: 0.004194568642966245 Accuracy 90.8318302068302\n",
      "epoch 6 / 10 running_loss: 0.0040717557390614655 Accuracy 91.10612552107457\n",
      "epoch 6 / 10 running_loss: 0.003955604724389588 Accuracy 91.36528584189371\n",
      "epoch 7 / 10 running_loss: 0.0038408501097855373 Accuracy 91.61958771778507\n",
      "epoch 7 / 10 running_loss: 0.0037328234075074103 Accuracy 91.85530265132566\n",
      "epoch 7 / 10 running_loss: 0.003636731557307511 Accuracy 92.06975149265774\n",
      "epoch 7 / 10 running_loss: 0.0035425071637351408 Accuracy 92.27640886352978\n",
      "epoch 8 / 10 running_loss: 0.0034547455198530768 Accuracy 92.47043886909725\n",
      "epoch 8 / 10 running_loss: 0.003365828645095615 Accuracy 92.66580225115868\n",
      "epoch 8 / 10 running_loss: 0.0032844056148944585 Accuracy 92.84731651540056\n",
      "epoch 8 / 10 running_loss: 0.003210355737826582 Accuracy 93.01287952476899\n",
      "epoch 8 / 10 running_loss: 0.0031396373296867734 Accuracy 93.1684327046576\n",
      "epoch 9 / 10 running_loss: 0.0030686169818580425 Accuracy 93.3237888362296\n",
      "epoch 9 / 10 running_loss: 0.0030019353411961775 Accuracy 93.46920696511032\n",
      "epoch 9 / 10 running_loss: 0.002937959362259841 Accuracy 93.61106334417208\n",
      "epoch 9 / 10 running_loss: 0.00287882961362021 Accuracy 93.74046791117618\n",
      "epoch 9 / 10 running_loss: 0.0028216913005960145 Accuracy 93.86463792282039\n",
      "epoch 10 / 10 running_loss: 0.0027651543510263162 Accuracy 93.98740620091908\n",
      "epoch 10 / 10 running_loss: 0.002709655751517608 Accuracy 94.10884827468593\n",
      "epoch 10 / 10 running_loss: 0.002661506073863948 Accuracy 94.21394725140348\n",
      "epoch 10 / 10 running_loss: 0.002614073339624531 Accuracy 94.31838263280953\n"
     ]
    }
   ],
   "source": [
    "#torch.set_printoptions(precision=2)\n",
    "def train_function(train_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for input,label in iter(train_loader):\n",
    "\n",
    "            #input.resize_(input.size()[0], 784)   take to forward\n",
    "            y_pred=model(input)   #this is 64 (bacth_size)*10\n",
    "\n",
    "            if(count==0): print(y_pred.size(),label.size())\n",
    "            loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "            loss_running=loss_running+loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count=count+1\n",
    "            #y_pred_round=torch.round(y_pred)\n",
    "            count_batch=count_batch+(label.size()[0])\n",
    "            _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "            acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "            sum_acc=sum_acc+acc\n",
    "            if(count%200==0): print('epoch',epoch+1,'/',epochs,'running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "\n",
    "        check_loss=(loss_running/count_batch)\n",
    "        lr_scheduler_.step(check_loss)\n",
    "\n",
    "train_function(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_loss: 0.0010182581818116887 Accuracy 98.28125\n"
     ]
    }
   ],
   "source": [
    "#torch.set_printoptions(precision=2)\n",
    "def test_function(test_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "\n",
    "\n",
    "    for input,label in iter(test_loader):\n",
    "        model.eval()\n",
    "\n",
    "        #input.resize_(input.size()[0], 784)   take to forward\n",
    "        y_pred=model(input)   #this is 64 (bacth_size)*10\n",
    "\n",
    "        #if(count==0): print(y_pred.size(),label.size())\n",
    "        loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "        loss_running=loss_running+loss.item()\n",
    "        count=count+1\n",
    "\n",
    "        count_batch=count_batch+(label.size()[0])\n",
    "        _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "        acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "        sum_acc=sum_acc+acc\n",
    "        if(count%100==0): print('running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_function(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
