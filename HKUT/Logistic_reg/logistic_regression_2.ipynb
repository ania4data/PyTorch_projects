{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=Variable(torch.tensor([[1.0],[2.0],[3.0],[4.0]]))  # this makes is 3*1,  only one feature, require grad default to false\n",
    "y_data=Variable(torch.tensor([[-1.0],[-1.0],[1.0],[1.0]]))   #Variable:Wraps a tensor and records the operations applied to it\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()   #call in the init of the nn.Module\n",
    "        self.fc1=torch.nn.Linear(1,1)  #one feature in, one feature out 1*1\n",
    "        #self.relu1=torch.nn.ReLU()\n",
    "        #self.tanh1 = torch.nn.Tanh()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):  \n",
    "        \n",
    "        #y_pred=F.sigmoid(self.fc1(x))\n",
    "        #t=self.tanh1(self.fc1(x))\n",
    "        t=self.fc1(x)\n",
    "        t=F.tanh(t)     #in order to use tanh since it keep the out put between -1 and 1, need to modify ytarget to -1 and 1\n",
    "                        # also the binary BCF loss would not work for -1 and 1 (need 0,1 ) so had to change loss function to\n",
    "                        # torch.nn.SoftMarginLoss target tensor y (containing 1 or -1)\n",
    "        #t=torch.nn.Tanh(t)\n",
    "        #t=self.relu1(t)\n",
    "        #t=F.softmax(t,dim=0)\n",
    "        #y_pred=self.soft1(t)\n",
    "        y_pred=t\n",
    "        \n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Model(\n",
      "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5718])\n",
      "tensor(0.9330)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters(): print((parameter[0]))   #initillizing it on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.5718]]), Parameter containing:\n",
       " tensor([ 0.9330])]"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion=torch.nn.BCELoss(size_average=True)   #loss initilization, binary cross entropy need to be 0,1 y\n",
    "#criterion=torch.nn.HingeEmbeddingLoss(margin=0.0)  #soso\n",
    "criterion=torch.nn.SoftMarginLoss()\n",
    "#criterion=torch.nn.CrossEntropyLoss()\n",
    "#criterion=torch.nn.NLLLoss()\n",
    "#optimizer=torch.optim.SGD(model.parameters(),lr=0.01)  #init SGD with initilized model.paramter  (w/ grad, weight and bias)\n",
    "#optimizer=torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "#optimizer=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "#torch.optim will hold the current state and will update the parameters based on the computed gradients. iterable containing the parameters (Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: tensor(0.9430) 1.0 tensor([ 0.3466]) 4.0 tensor([-0.8675]) 7.0 tensor([-0.9951])\n",
      "epoch: 5 loss: tensor(0.9283) 1.0 tensor([ 0.3779]) 4.0 tensor([-0.7811]) 7.0 tensor([-0.9865])\n",
      "epoch: 10 loss: tensor(0.8731) 1.0 tensor([ 0.5084]) 4.0 tensor([-0.3318]) 7.0 tensor([-0.8483])\n",
      "epoch: 15 loss: tensor(0.7702) 1.0 tensor([ 0.6420]) 4.0 tensor([ 0.4443]) 7.0 tensor([ 0.1911])\n",
      "epoch: 20 loss: tensor(0.7522) 1.0 tensor([ 0.6641]) 4.0 tensor([ 0.6264]) 7.0 tensor([ 0.5854])\n",
      "epoch: 25 loss: tensor(0.7458) 1.0 tensor([ 0.6578]) 4.0 tensor([ 0.6761]) 7.0 tensor([ 0.6936])\n",
      "epoch: 30 loss: tensor(0.7404) 1.0 tensor([ 0.6409]) 4.0 tensor([ 0.6906]) 7.0 tensor([ 0.7345])\n",
      "epoch: 35 loss: tensor(0.7349) 1.0 tensor([ 0.6178]) 4.0 tensor([ 0.6911]) 7.0 tensor([ 0.7526])\n",
      "epoch: 40 loss: tensor(0.7289) 1.0 tensor([ 0.5903]) 4.0 tensor([ 0.6853]) 7.0 tensor([ 0.7615])\n",
      "epoch: 45 loss: tensor(0.7224) 1.0 tensor([ 0.5592]) 4.0 tensor([ 0.6765]) 7.0 tensor([ 0.7672])\n",
      "epoch: 50 loss: tensor(0.7154) 1.0 tensor([ 0.5249]) 4.0 tensor([ 0.6665]) 7.0 tensor([ 0.7722])\n",
      "epoch: 55 loss: tensor(0.7078) 1.0 tensor([ 0.4876]) 4.0 tensor([ 0.6565]) 7.0 tensor([ 0.7780])\n",
      "epoch: 60 loss: tensor(0.6997) 1.0 tensor([ 0.4476]) 4.0 tensor([ 0.6472]) 7.0 tensor([ 0.7854])\n",
      "epoch: 65 loss: tensor(0.6911) 1.0 tensor([ 0.4052]) 4.0 tensor([ 0.6391]) 7.0 tensor([ 0.7945])\n",
      "epoch: 70 loss: tensor(0.6821) 1.0 tensor([ 0.3606]) 4.0 tensor([ 0.6326]) 7.0 tensor([ 0.8054])\n",
      "epoch: 75 loss: tensor(0.6727) 1.0 tensor([ 0.3143]) 4.0 tensor([ 0.6279]) 7.0 tensor([ 0.8179])\n",
      "epoch: 80 loss: tensor(0.6630) 1.0 tensor([ 0.2667]) 4.0 tensor([ 0.6250]) 7.0 tensor([ 0.8316])\n",
      "epoch: 85 loss: tensor(0.6531) 1.0 tensor([ 0.2182]) 4.0 tensor([ 0.6242]) 7.0 tensor([ 0.8460])\n",
      "epoch: 90 loss: tensor(0.6432) 1.0 tensor([ 0.1693]) 4.0 tensor([ 0.6254]) 7.0 tensor([ 0.8608])\n",
      "epoch: 95 loss: tensor(0.6332) 1.0 tensor([ 0.1205]) 4.0 tensor([ 0.6283]) 7.0 tensor([ 0.8755])\n",
      "epoch: 100 loss: tensor(0.6234) 1.0 tensor(1.00000e-02 *\n",
      "       [ 7.2258]) 4.0 tensor([ 0.6329]) 7.0 tensor([ 0.8896])\n",
      "epoch: 105 loss: tensor(0.6137) 1.0 tensor(1.00000e-02 *\n",
      "       [ 2.4857]) 4.0 tensor([ 0.6389]) 7.0 tensor([ 0.9029])\n",
      "epoch: 110 loss: tensor(0.6043) 1.0 tensor(1.00000e-02 *\n",
      "       [-2.1346]) 4.0 tensor([ 0.6461]) 7.0 tensor([ 0.9152])\n",
      "epoch: 115 loss: tensor(0.5951) 1.0 tensor(1.00000e-02 *\n",
      "       [-6.6101]) 4.0 tensor([ 0.6542]) 7.0 tensor([ 0.9263])\n",
      "epoch: 120 loss: tensor(0.5863) 1.0 tensor([-0.1092]) 4.0 tensor([ 0.6631]) 7.0 tensor([ 0.9362])\n",
      "epoch: 125 loss: tensor(0.5779) 1.0 tensor([-0.1506]) 4.0 tensor([ 0.6724]) 7.0 tensor([ 0.9449])\n",
      "epoch: 130 loss: tensor(0.5698) 1.0 tensor([-0.1901]) 4.0 tensor([ 0.6820]) 7.0 tensor([ 0.9525])\n",
      "epoch: 135 loss: tensor(0.5622) 1.0 tensor([-0.2277]) 4.0 tensor([ 0.6918]) 7.0 tensor([ 0.9591])\n",
      "epoch: 140 loss: tensor(0.5549) 1.0 tensor([-0.2634]) 4.0 tensor([ 0.7016]) 7.0 tensor([ 0.9648])\n",
      "epoch: 145 loss: tensor(0.5479) 1.0 tensor([-0.2973]) 4.0 tensor([ 0.7113]) 7.0 tensor([ 0.9696])\n",
      "epoch: 150 loss: tensor(0.5414) 1.0 tensor([-0.3294]) 4.0 tensor([ 0.7209]) 7.0 tensor([ 0.9738])\n",
      "epoch: 155 loss: tensor(0.5352) 1.0 tensor([-0.3597]) 4.0 tensor([ 0.7303]) 7.0 tensor([ 0.9774])\n",
      "epoch: 160 loss: tensor(0.5293) 1.0 tensor([-0.3883]) 4.0 tensor([ 0.7394]) 7.0 tensor([ 0.9804])\n",
      "epoch: 165 loss: tensor(0.5237) 1.0 tensor([-0.4153]) 4.0 tensor([ 0.7482]) 7.0 tensor([ 0.9830])\n",
      "epoch: 170 loss: tensor(0.5185) 1.0 tensor([-0.4408]) 4.0 tensor([ 0.7567]) 7.0 tensor([ 0.9852])\n",
      "epoch: 175 loss: tensor(0.5135) 1.0 tensor([-0.4649]) 4.0 tensor([ 0.7649]) 7.0 tensor([ 0.9871])\n",
      "epoch: 180 loss: tensor(0.5088) 1.0 tensor([-0.4876]) 4.0 tensor([ 0.7728]) 7.0 tensor([ 0.9888])\n",
      "epoch: 185 loss: tensor(0.5043) 1.0 tensor([-0.5090]) 4.0 tensor([ 0.7804]) 7.0 tensor([ 0.9901])\n",
      "epoch: 190 loss: tensor(0.5001) 1.0 tensor([-0.5292]) 4.0 tensor([ 0.7876]) 7.0 tensor([ 0.9913])\n",
      "epoch: 195 loss: tensor(0.4960) 1.0 tensor([-0.5483]) 4.0 tensor([ 0.7946]) 7.0 tensor([ 0.9924])\n",
      "epoch: 200 loss: tensor(0.4922) 1.0 tensor([-0.5664]) 4.0 tensor([ 0.8012]) 7.0 tensor([ 0.9933])\n",
      "epoch: 205 loss: tensor(0.4886) 1.0 tensor([-0.5834]) 4.0 tensor([ 0.8076]) 7.0 tensor([ 0.9941])\n",
      "epoch: 210 loss: tensor(0.4851) 1.0 tensor([-0.5995]) 4.0 tensor([ 0.8137]) 7.0 tensor([ 0.9947])\n",
      "epoch: 215 loss: tensor(0.4818) 1.0 tensor([-0.6148]) 4.0 tensor([ 0.8195]) 7.0 tensor([ 0.9953])\n",
      "epoch: 220 loss: tensor(0.4786) 1.0 tensor([-0.6292]) 4.0 tensor([ 0.8251]) 7.0 tensor([ 0.9958])\n",
      "epoch: 225 loss: tensor(0.4756) 1.0 tensor([-0.6429]) 4.0 tensor([ 0.8304]) 7.0 tensor([ 0.9963])\n",
      "epoch: 230 loss: tensor(0.4728) 1.0 tensor([-0.6559]) 4.0 tensor([ 0.8355]) 7.0 tensor([ 0.9967])\n",
      "epoch: 235 loss: tensor(0.4700) 1.0 tensor([-0.6682]) 4.0 tensor([ 0.8404]) 7.0 tensor([ 0.9970])\n",
      "epoch: 240 loss: tensor(0.4674) 1.0 tensor([-0.6799]) 4.0 tensor([ 0.8451]) 7.0 tensor([ 0.9973])\n",
      "epoch: 245 loss: tensor(0.4648) 1.0 tensor([-0.6910]) 4.0 tensor([ 0.8496]) 7.0 tensor([ 0.9976])\n",
      "epoch: 250 loss: tensor(0.4624) 1.0 tensor([-0.7016]) 4.0 tensor([ 0.8539]) 7.0 tensor([ 0.9978])\n",
      "epoch: 255 loss: tensor(0.4601) 1.0 tensor([-0.7116]) 4.0 tensor([ 0.8580]) 7.0 tensor([ 0.9980])\n",
      "epoch: 260 loss: tensor(0.4578) 1.0 tensor([-0.7212]) 4.0 tensor([ 0.8620]) 7.0 tensor([ 0.9982])\n",
      "epoch: 265 loss: tensor(0.4557) 1.0 tensor([-0.7303]) 4.0 tensor([ 0.8658]) 7.0 tensor([ 0.9984])\n",
      "epoch: 270 loss: tensor(0.4536) 1.0 tensor([-0.7390]) 4.0 tensor([ 0.8694]) 7.0 tensor([ 0.9985])\n",
      "epoch: 275 loss: tensor(0.4516) 1.0 tensor([-0.7473]) 4.0 tensor([ 0.8729]) 7.0 tensor([ 0.9987])\n",
      "epoch: 280 loss: tensor(0.4497) 1.0 tensor([-0.7552]) 4.0 tensor([ 0.8763]) 7.0 tensor([ 0.9988])\n",
      "epoch: 285 loss: tensor(0.4478) 1.0 tensor([-0.7628]) 4.0 tensor([ 0.8795]) 7.0 tensor([ 0.9989])\n",
      "epoch: 290 loss: tensor(0.4460) 1.0 tensor([-0.7700]) 4.0 tensor([ 0.8827]) 7.0 tensor([ 0.9990])\n",
      "epoch: 295 loss: tensor(0.4443) 1.0 tensor([-0.7769]) 4.0 tensor([ 0.8857]) 7.0 tensor([ 0.9991])\n",
      "epoch: 300 loss: tensor(0.4426) 1.0 tensor([-0.7836]) 4.0 tensor([ 0.8886]) 7.0 tensor([ 0.9992])\n",
      "epoch: 305 loss: tensor(0.4410) 1.0 tensor([-0.7899]) 4.0 tensor([ 0.8913]) 7.0 tensor([ 0.9992])\n",
      "epoch: 310 loss: tensor(0.4394) 1.0 tensor([-0.7960]) 4.0 tensor([ 0.8940]) 7.0 tensor([ 0.9993])\n",
      "epoch: 315 loss: tensor(0.4379) 1.0 tensor([-0.8018]) 4.0 tensor([ 0.8966]) 7.0 tensor([ 0.9993])\n",
      "epoch: 320 loss: tensor(0.4364) 1.0 tensor([-0.8074]) 4.0 tensor([ 0.8991]) 7.0 tensor([ 0.9994])\n",
      "epoch: 325 loss: tensor(0.4349) 1.0 tensor([-0.8127]) 4.0 tensor([ 0.9015]) 7.0 tensor([ 0.9994])\n",
      "epoch: 330 loss: tensor(0.4336) 1.0 tensor([-0.8179]) 4.0 tensor([ 0.9039]) 7.0 tensor([ 0.9995])\n",
      "epoch: 335 loss: tensor(0.4322) 1.0 tensor([-0.8228]) 4.0 tensor([ 0.9061]) 7.0 tensor([ 0.9995])\n",
      "epoch: 340 loss: tensor(0.4309) 1.0 tensor([-0.8276]) 4.0 tensor([ 0.9083]) 7.0 tensor([ 0.9996])\n",
      "epoch: 345 loss: tensor(0.4296) 1.0 tensor([-0.8321]) 4.0 tensor([ 0.9104]) 7.0 tensor([ 0.9996])\n",
      "epoch: 350 loss: tensor(0.4284) 1.0 tensor([-0.8365]) 4.0 tensor([ 0.9124]) 7.0 tensor([ 0.9996])\n",
      "epoch: 355 loss: tensor(0.4271) 1.0 tensor([-0.8407]) 4.0 tensor([ 0.9144]) 7.0 tensor([ 0.9997])\n",
      "epoch: 360 loss: tensor(0.4260) 1.0 tensor([-0.8448]) 4.0 tensor([ 0.9163]) 7.0 tensor([ 0.9997])\n",
      "epoch: 365 loss: tensor(0.4248) 1.0 tensor([-0.8487]) 4.0 tensor([ 0.9181]) 7.0 tensor([ 0.9997])\n",
      "epoch: 370 loss: tensor(0.4237) 1.0 tensor([-0.8525]) 4.0 tensor([ 0.9199]) 7.0 tensor([ 0.9997])\n",
      "epoch: 375 loss: tensor(0.4226) 1.0 tensor([-0.8562]) 4.0 tensor([ 0.9216]) 7.0 tensor([ 0.9997])\n",
      "epoch: 380 loss: tensor(0.4215) 1.0 tensor([-0.8597]) 4.0 tensor([ 0.9233]) 7.0 tensor([ 0.9998])\n",
      "epoch: 385 loss: tensor(0.4205) 1.0 tensor([-0.8631]) 4.0 tensor([ 0.9249]) 7.0 tensor([ 0.9998])\n",
      "epoch: 390 loss: tensor(0.4195) 1.0 tensor([-0.8664]) 4.0 tensor([ 0.9265]) 7.0 tensor([ 0.9998])\n",
      "epoch: 395 loss: tensor(0.4185) 1.0 tensor([-0.8695]) 4.0 tensor([ 0.9280]) 7.0 tensor([ 0.9998])\n",
      "epoch: 400 loss: tensor(0.4175) 1.0 tensor([-0.8726]) 4.0 tensor([ 0.9295]) 7.0 tensor([ 0.9998])\n",
      "epoch: 405 loss: tensor(0.4166) 1.0 tensor([-0.8756]) 4.0 tensor([ 0.9310]) 7.0 tensor([ 0.9998])\n",
      "epoch: 410 loss: tensor(0.4157) 1.0 tensor([-0.8784]) 4.0 tensor([ 0.9324]) 7.0 tensor([ 0.9998])\n",
      "epoch: 415 loss: tensor(0.4148) 1.0 tensor([-0.8812]) 4.0 tensor([ 0.9337]) 7.0 tensor([ 0.9999])\n",
      "epoch: 420 loss: tensor(0.4139) 1.0 tensor([-0.8839]) 4.0 tensor([ 0.9350]) 7.0 tensor([ 0.9999])\n",
      "epoch: 425 loss: tensor(0.4130) 1.0 tensor([-0.8865]) 4.0 tensor([ 0.9363]) 7.0 tensor([ 0.9999])\n",
      "epoch: 430 loss: tensor(0.4122) 1.0 tensor([-0.8890]) 4.0 tensor([ 0.9376]) 7.0 tensor([ 0.9999])\n",
      "epoch: 435 loss: tensor(0.4113) 1.0 tensor([-0.8914]) 4.0 tensor([ 0.9388]) 7.0 tensor([ 0.9999])\n",
      "epoch: 440 loss: tensor(0.4105) 1.0 tensor([-0.8937]) 4.0 tensor([ 0.9400]) 7.0 tensor([ 0.9999])\n",
      "epoch: 445 loss: tensor(0.4097) 1.0 tensor([-0.8960]) 4.0 tensor([ 0.9411]) 7.0 tensor([ 0.9999])\n",
      "epoch: 450 loss: tensor(0.4089) 1.0 tensor([-0.8982]) 4.0 tensor([ 0.9422]) 7.0 tensor([ 0.9999])\n",
      "epoch: 455 loss: tensor(0.4082) 1.0 tensor([-0.9004]) 4.0 tensor([ 0.9433]) 7.0 tensor([ 0.9999])\n",
      "epoch: 460 loss: tensor(0.4074) 1.0 tensor([-0.9025]) 4.0 tensor([ 0.9444]) 7.0 tensor([ 0.9999])\n",
      "epoch: 465 loss: tensor(0.4067) 1.0 tensor([-0.9045]) 4.0 tensor([ 0.9454]) 7.0 tensor([ 0.9999])\n",
      "epoch: 470 loss: tensor(0.4060) 1.0 tensor([-0.9065]) 4.0 tensor([ 0.9464]) 7.0 tensor([ 0.9999])\n",
      "epoch: 475 loss: tensor(0.4053) 1.0 tensor([-0.9084]) 4.0 tensor([ 0.9474]) 7.0 tensor([ 0.9999])\n",
      "epoch: 480 loss: tensor(0.4046) 1.0 tensor([-0.9102]) 4.0 tensor([ 0.9483]) 7.0 tensor([ 0.9999])\n",
      "epoch: 485 loss: tensor(0.4039) 1.0 tensor([-0.9120]) 4.0 tensor([ 0.9493]) 7.0 tensor([ 0.9999])\n",
      "epoch: 490 loss: tensor(0.4032) 1.0 tensor([-0.9138]) 4.0 tensor([ 0.9502]) 7.0 tensor([ 0.9999])\n",
      "epoch: 495 loss: tensor(0.4026) 1.0 tensor([-0.9155]) 4.0 tensor([ 0.9510]) 7.0 tensor([ 0.9999])\n"
     ]
    }
   ],
   "source": [
    "loss_=torch.tensor([])\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #for parameter in model.parameters(): print('epoch',epoch,parameter[0]) \n",
    "    y_pred=model(x_data)   #this automtically call forward\n",
    "    loss=criterion(y_pred,y_data)\n",
    "    \n",
    "    \n",
    "    tmp=torch.tensor([loss])\n",
    "    loss_=torch.cat((loss_,tmp))\n",
    "    optimizer.zero_grad()   #initilize gradient to zero before every step, to avoid accumulation ,zero off good for RNN\n",
    "    loss.backward()         #calculate gradient\n",
    "    optimizer.step()        #update parameter (weights)\n",
    "    t0=torch.tensor([1.0])\n",
    "    t1=torch.tensor([4.0])\n",
    "    t2=torch.tensor([7.0])\n",
    "    output0=model.forward(t0)\n",
    "    output1=model.forward(t1)\n",
    "    output2=model.forward(t2)\n",
    "    #_, predicted0=torch.max(output0.data, 1)\n",
    "    #_, predicted1=torch.max(output1.data, 1)\n",
    "    #_, predicted2=torch.max(output2.data, 1)\n",
    "    if(epoch%5==0): print('epoch:',epoch,'loss:',loss,'1.0',output0,'4.0',output1,'7.0',output2)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.1394])\n",
      "tensor(-2.7079)\n"
     ]
    }
   ],
   "source": [
    "for i,parameter in enumerate(model.parameters()):\n",
    "    #print('w:',list(model.parameters()[0]),'bias:',list(model.parameters()[0])) \n",
    "\n",
    "    print(parameter[0])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_softmax_tan=loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.arange(0,epochs,1),loss_SGD_01.detach().numpy(),label='SGD_0.1_sigmoid')  #lr=0.01 #need to detach gradient for graph breakdown otherwise won't do numpy in the middle of graph (good for end of run)\n",
    "plt.plot(np.arange(0,epochs,1),loss_softmax_tan.detach().numpy(),label='SGD_softmax_tan') \n",
    "#plt.plot(np.arange(0,epochs,1),loss_sgd_mom.detach().numpy(),label='SGD_0.01_mom_0.9')   #lr=0.01 momentum=0.9\n",
    "#plt.plot(np.arange(0,epochs,1),loss_Adam.detach().numpy(),label='Adam_0.1') #lr=0.1\n",
    "#plt.xlim([-1,40])\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "\n",
    "#SGD w/o momentum look better in converging, than with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6775)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=torch.tensor([4.0])\n",
    "model.forward(test).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
