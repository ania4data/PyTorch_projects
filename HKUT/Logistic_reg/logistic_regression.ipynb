{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=Variable(torch.tensor([[1.0],[2.0],[3.0],[4.0]]))  # this makes is 3*1,  only one feature, require grad default to false\n",
    "y_data=Variable(torch.tensor([[0.0],[0.0],[1.0],[1.0]]))   #Variable:Wraps a tensor and records the operations applied to it\n",
    "epochs=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()   #call in the init of the nn.Module\n",
    "        self.fc1=torch.nn.Linear(1,1)  #one feature in, one feature out 1*1\n",
    "        \n",
    "    def forward(self,x):  \n",
    "        \n",
    "        y_pred=F.sigmoid(self.fc1(x))\n",
    "        \n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Model(\n",
      "  (fc1): Linear(in_features=1, out_features=1, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2741])\n",
      "tensor(-0.3809)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters(): print((parameter[0]))   #initillizing it on its own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2741]]), Parameter containing:\n",
       " tensor([-0.3809])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=torch.nn.BCELoss(size_average=True)   #loss initilization, binary cross entropy\n",
    "#optimizer=torch.optim.SGD(model.parameters(),lr=0.01)  #init SGD with initilized model.paramter  (w/ grad, weight and bias)\n",
    "#optimizer=torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "#optimizer=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "\n",
    "#torch.optim will hold the current state and will update the parameters based on the computed gradients. iterable containing the parameters (Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: tensor(0.5790) 2.0 tensor([ 0.5514]) 4.0 tensor([ 0.6902]) 7.0 tensor([ 0.8447])\n",
      "epoch: 5 loss: tensor(0.5596) 2.0 tensor([ 0.5762]) 4.0 tensor([ 0.7413]) 7.0 tensor([ 0.8976])\n",
      "epoch: 10 loss: tensor(0.5482) 2.0 tensor([ 0.5823]) 4.0 tensor([ 0.7620]) 7.0 tensor([ 0.9177])\n",
      "epoch: 15 loss: tensor(0.5382) 2.0 tensor([ 0.5819]) 4.0 tensor([ 0.7727]) 7.0 tensor([ 0.9285])\n",
      "epoch: 20 loss: tensor(0.5286) 2.0 tensor([ 0.5791]) 4.0 tensor([ 0.7798]) 7.0 tensor([ 0.9360])\n",
      "epoch: 25 loss: tensor(0.5194) 2.0 tensor([ 0.5753]) 4.0 tensor([ 0.7853]) 7.0 tensor([ 0.9419])\n",
      "epoch: 30 loss: tensor(0.5105) 2.0 tensor([ 0.5713]) 4.0 tensor([ 0.7902]) 7.0 tensor([ 0.9471])\n",
      "epoch: 35 loss: tensor(0.5019) 2.0 tensor([ 0.5672]) 4.0 tensor([ 0.7948]) 7.0 tensor([ 0.9516])\n",
      "epoch: 40 loss: tensor(0.4936) 2.0 tensor([ 0.5631]) 4.0 tensor([ 0.7992]) 7.0 tensor([ 0.9557])\n",
      "epoch: 45 loss: tensor(0.4856) 2.0 tensor([ 0.5590]) 4.0 tensor([ 0.8034]) 7.0 tensor([ 0.9594])\n",
      "epoch: 50 loss: tensor(0.4778) 2.0 tensor([ 0.5550]) 4.0 tensor([ 0.8075]) 7.0 tensor([ 0.9628])\n",
      "epoch: 55 loss: tensor(0.4703) 2.0 tensor([ 0.5511]) 4.0 tensor([ 0.8115]) 7.0 tensor([ 0.9658])\n",
      "epoch: 60 loss: tensor(0.4630) 2.0 tensor([ 0.5473]) 4.0 tensor([ 0.8154]) 7.0 tensor([ 0.9686])\n",
      "epoch: 65 loss: tensor(0.4560) 2.0 tensor([ 0.5435]) 4.0 tensor([ 0.8191]) 7.0 tensor([ 0.9711])\n",
      "epoch: 70 loss: tensor(0.4491) 2.0 tensor([ 0.5398]) 4.0 tensor([ 0.8228]) 7.0 tensor([ 0.9734])\n",
      "epoch: 75 loss: tensor(0.4425) 2.0 tensor([ 0.5362]) 4.0 tensor([ 0.8264]) 7.0 tensor([ 0.9755])\n",
      "epoch: 80 loss: tensor(0.4361) 2.0 tensor([ 0.5326]) 4.0 tensor([ 0.8299]) 7.0 tensor([ 0.9774])\n",
      "epoch: 85 loss: tensor(0.4300) 2.0 tensor([ 0.5292]) 4.0 tensor([ 0.8332]) 7.0 tensor([ 0.9791])\n",
      "epoch: 90 loss: tensor(0.4239) 2.0 tensor([ 0.5257]) 4.0 tensor([ 0.8365]) 7.0 tensor([ 0.9807])\n",
      "epoch: 95 loss: tensor(0.4181) 2.0 tensor([ 0.5224]) 4.0 tensor([ 0.8397]) 7.0 tensor([ 0.9821])\n",
      "epoch: 100 loss: tensor(0.4125) 2.0 tensor([ 0.5191]) 4.0 tensor([ 0.8429]) 7.0 tensor([ 0.9834])\n",
      "epoch: 105 loss: tensor(0.4070) 2.0 tensor([ 0.5158]) 4.0 tensor([ 0.8459]) 7.0 tensor([ 0.9847])\n",
      "epoch: 110 loss: tensor(0.4017) 2.0 tensor([ 0.5127]) 4.0 tensor([ 0.8488]) 7.0 tensor([ 0.9858])\n",
      "epoch: 115 loss: tensor(0.3965) 2.0 tensor([ 0.5095]) 4.0 tensor([ 0.8517]) 7.0 tensor([ 0.9868])\n",
      "epoch: 120 loss: tensor(0.3915) 2.0 tensor([ 0.5065]) 4.0 tensor([ 0.8545]) 7.0 tensor([ 0.9877])\n",
      "epoch: 125 loss: tensor(0.3866) 2.0 tensor([ 0.5034]) 4.0 tensor([ 0.8572]) 7.0 tensor([ 0.9886])\n",
      "epoch: 130 loss: tensor(0.3819) 2.0 tensor([ 0.5005]) 4.0 tensor([ 0.8599]) 7.0 tensor([ 0.9894])\n",
      "epoch: 135 loss: tensor(0.3773) 2.0 tensor([ 0.4976]) 4.0 tensor([ 0.8624]) 7.0 tensor([ 0.9901])\n",
      "epoch: 140 loss: tensor(0.3728) 2.0 tensor([ 0.4947]) 4.0 tensor([ 0.8650]) 7.0 tensor([ 0.9908])\n",
      "epoch: 145 loss: tensor(0.3685) 2.0 tensor([ 0.4919]) 4.0 tensor([ 0.8674]) 7.0 tensor([ 0.9914])\n",
      "epoch: 150 loss: tensor(0.3642) 2.0 tensor([ 0.4891]) 4.0 tensor([ 0.8698]) 7.0 tensor([ 0.9919])\n",
      "epoch: 155 loss: tensor(0.3601) 2.0 tensor([ 0.4864]) 4.0 tensor([ 0.8721]) 7.0 tensor([ 0.9925])\n",
      "epoch: 160 loss: tensor(0.3561) 2.0 tensor([ 0.4837]) 4.0 tensor([ 0.8744]) 7.0 tensor([ 0.9930])\n",
      "epoch: 165 loss: tensor(0.3522) 2.0 tensor([ 0.4811]) 4.0 tensor([ 0.8766]) 7.0 tensor([ 0.9934])\n",
      "epoch: 170 loss: tensor(0.3484) 2.0 tensor([ 0.4785]) 4.0 tensor([ 0.8787]) 7.0 tensor([ 0.9938])\n",
      "epoch: 175 loss: tensor(0.3447) 2.0 tensor([ 0.4759]) 4.0 tensor([ 0.8808]) 7.0 tensor([ 0.9942])\n",
      "epoch: 180 loss: tensor(0.3411) 2.0 tensor([ 0.4734]) 4.0 tensor([ 0.8828]) 7.0 tensor([ 0.9946])\n",
      "epoch: 185 loss: tensor(0.3375) 2.0 tensor([ 0.4709]) 4.0 tensor([ 0.8848]) 7.0 tensor([ 0.9949])\n",
      "epoch: 190 loss: tensor(0.3341) 2.0 tensor([ 0.4685]) 4.0 tensor([ 0.8868]) 7.0 tensor([ 0.9952])\n",
      "epoch: 195 loss: tensor(0.3308) 2.0 tensor([ 0.4661]) 4.0 tensor([ 0.8886]) 7.0 tensor([ 0.9955])\n",
      "epoch: 200 loss: tensor(0.3275) 2.0 tensor([ 0.4637]) 4.0 tensor([ 0.8905]) 7.0 tensor([ 0.9958])\n",
      "epoch: 205 loss: tensor(0.3243) 2.0 tensor([ 0.4613]) 4.0 tensor([ 0.8923]) 7.0 tensor([ 0.9960])\n",
      "epoch: 210 loss: tensor(0.3212) 2.0 tensor([ 0.4590]) 4.0 tensor([ 0.8940]) 7.0 tensor([ 0.9962])\n",
      "epoch: 215 loss: tensor(0.3181) 2.0 tensor([ 0.4568]) 4.0 tensor([ 0.8958]) 7.0 tensor([ 0.9964])\n",
      "epoch: 220 loss: tensor(0.3152) 2.0 tensor([ 0.4545]) 4.0 tensor([ 0.8974]) 7.0 tensor([ 0.9967])\n",
      "epoch: 225 loss: tensor(0.3123) 2.0 tensor([ 0.4523]) 4.0 tensor([ 0.8991]) 7.0 tensor([ 0.9968])\n",
      "epoch: 230 loss: tensor(0.3094) 2.0 tensor([ 0.4502]) 4.0 tensor([ 0.9006]) 7.0 tensor([ 0.9970])\n",
      "epoch: 235 loss: tensor(0.3066) 2.0 tensor([ 0.4480]) 4.0 tensor([ 0.9022]) 7.0 tensor([ 0.9972])\n",
      "epoch: 240 loss: tensor(0.3039) 2.0 tensor([ 0.4459]) 4.0 tensor([ 0.9037]) 7.0 tensor([ 0.9973])\n",
      "epoch: 245 loss: tensor(0.3013) 2.0 tensor([ 0.4438]) 4.0 tensor([ 0.9052]) 7.0 tensor([ 0.9975])\n",
      "epoch: 250 loss: tensor(0.2987) 2.0 tensor([ 0.4418]) 4.0 tensor([ 0.9067]) 7.0 tensor([ 0.9976])\n",
      "epoch: 255 loss: tensor(0.2961) 2.0 tensor([ 0.4398]) 4.0 tensor([ 0.9081]) 7.0 tensor([ 0.9977])\n",
      "epoch: 260 loss: tensor(0.2936) 2.0 tensor([ 0.4378]) 4.0 tensor([ 0.9095]) 7.0 tensor([ 0.9979])\n",
      "epoch: 265 loss: tensor(0.2912) 2.0 tensor([ 0.4358]) 4.0 tensor([ 0.9108]) 7.0 tensor([ 0.9980])\n",
      "epoch: 270 loss: tensor(0.2888) 2.0 tensor([ 0.4338]) 4.0 tensor([ 0.9121]) 7.0 tensor([ 0.9981])\n",
      "epoch: 275 loss: tensor(0.2865) 2.0 tensor([ 0.4319]) 4.0 tensor([ 0.9134]) 7.0 tensor([ 0.9982])\n",
      "epoch: 280 loss: tensor(0.2842) 2.0 tensor([ 0.4300]) 4.0 tensor([ 0.9147]) 7.0 tensor([ 0.9983])\n",
      "epoch: 285 loss: tensor(0.2820) 2.0 tensor([ 0.4281]) 4.0 tensor([ 0.9159]) 7.0 tensor([ 0.9983])\n",
      "epoch: 290 loss: tensor(0.2798) 2.0 tensor([ 0.4263]) 4.0 tensor([ 0.9171]) 7.0 tensor([ 0.9984])\n",
      "epoch: 295 loss: tensor(0.2776) 2.0 tensor([ 0.4244]) 4.0 tensor([ 0.9183]) 7.0 tensor([ 0.9985])\n",
      "epoch: 300 loss: tensor(0.2755) 2.0 tensor([ 0.4226]) 4.0 tensor([ 0.9195]) 7.0 tensor([ 0.9986])\n",
      "epoch: 305 loss: tensor(0.2734) 2.0 tensor([ 0.4209]) 4.0 tensor([ 0.9206]) 7.0 tensor([ 0.9986])\n",
      "epoch: 310 loss: tensor(0.2714) 2.0 tensor([ 0.4191]) 4.0 tensor([ 0.9217]) 7.0 tensor([ 0.9987])\n",
      "epoch: 315 loss: tensor(0.2694) 2.0 tensor([ 0.4173]) 4.0 tensor([ 0.9228]) 7.0 tensor([ 0.9988])\n",
      "epoch: 320 loss: tensor(0.2674) 2.0 tensor([ 0.4156]) 4.0 tensor([ 0.9239]) 7.0 tensor([ 0.9988])\n",
      "epoch: 325 loss: tensor(0.2655) 2.0 tensor([ 0.4139]) 4.0 tensor([ 0.9249]) 7.0 tensor([ 0.9989])\n",
      "epoch: 330 loss: tensor(0.2636) 2.0 tensor([ 0.4122]) 4.0 tensor([ 0.9260]) 7.0 tensor([ 0.9989])\n",
      "epoch: 335 loss: tensor(0.2618) 2.0 tensor([ 0.4106]) 4.0 tensor([ 0.9270]) 7.0 tensor([ 0.9990])\n",
      "epoch: 340 loss: tensor(0.2599) 2.0 tensor([ 0.4089]) 4.0 tensor([ 0.9279]) 7.0 tensor([ 0.9990])\n",
      "epoch: 345 loss: tensor(0.2582) 2.0 tensor([ 0.4073]) 4.0 tensor([ 0.9289]) 7.0 tensor([ 0.9991])\n",
      "epoch: 350 loss: tensor(0.2564) 2.0 tensor([ 0.4057]) 4.0 tensor([ 0.9298]) 7.0 tensor([ 0.9991])\n",
      "epoch: 355 loss: tensor(0.2547) 2.0 tensor([ 0.4041]) 4.0 tensor([ 0.9308]) 7.0 tensor([ 0.9992])\n",
      "epoch: 360 loss: tensor(0.2530) 2.0 tensor([ 0.4025]) 4.0 tensor([ 0.9317]) 7.0 tensor([ 0.9992])\n",
      "epoch: 365 loss: tensor(0.2513) 2.0 tensor([ 0.4010]) 4.0 tensor([ 0.9326]) 7.0 tensor([ 0.9992])\n",
      "epoch: 370 loss: tensor(0.2497) 2.0 tensor([ 0.3995]) 4.0 tensor([ 0.9334]) 7.0 tensor([ 0.9993])\n",
      "epoch: 375 loss: tensor(0.2481) 2.0 tensor([ 0.3979]) 4.0 tensor([ 0.9343]) 7.0 tensor([ 0.9993])\n",
      "epoch: 380 loss: tensor(0.2465) 2.0 tensor([ 0.3964]) 4.0 tensor([ 0.9351]) 7.0 tensor([ 0.9993])\n",
      "epoch: 385 loss: tensor(0.2449) 2.0 tensor([ 0.3949]) 4.0 tensor([ 0.9359]) 7.0 tensor([ 0.9994])\n",
      "epoch: 390 loss: tensor(0.2434) 2.0 tensor([ 0.3935]) 4.0 tensor([ 0.9367]) 7.0 tensor([ 0.9994])\n",
      "epoch: 395 loss: tensor(0.2419) 2.0 tensor([ 0.3920]) 4.0 tensor([ 0.9375]) 7.0 tensor([ 0.9994])\n",
      "epoch: 400 loss: tensor(0.2404) 2.0 tensor([ 0.3906]) 4.0 tensor([ 0.9383]) 7.0 tensor([ 0.9994])\n",
      "epoch: 405 loss: tensor(0.2389) 2.0 tensor([ 0.3891]) 4.0 tensor([ 0.9391]) 7.0 tensor([ 0.9995])\n",
      "epoch: 410 loss: tensor(0.2375) 2.0 tensor([ 0.3877]) 4.0 tensor([ 0.9398]) 7.0 tensor([ 0.9995])\n",
      "epoch: 415 loss: tensor(0.2361) 2.0 tensor([ 0.3863]) 4.0 tensor([ 0.9406]) 7.0 tensor([ 0.9995])\n",
      "epoch: 420 loss: tensor(0.2347) 2.0 tensor([ 0.3849]) 4.0 tensor([ 0.9413]) 7.0 tensor([ 0.9995])\n",
      "epoch: 425 loss: tensor(0.2333) 2.0 tensor([ 0.3836]) 4.0 tensor([ 0.9420]) 7.0 tensor([ 0.9995])\n",
      "epoch: 430 loss: tensor(0.2319) 2.0 tensor([ 0.3822]) 4.0 tensor([ 0.9427]) 7.0 tensor([ 0.9996])\n",
      "epoch: 435 loss: tensor(0.2306) 2.0 tensor([ 0.3809]) 4.0 tensor([ 0.9434]) 7.0 tensor([ 0.9996])\n",
      "epoch: 440 loss: tensor(0.2293) 2.0 tensor([ 0.3795]) 4.0 tensor([ 0.9440]) 7.0 tensor([ 0.9996])\n",
      "epoch: 445 loss: tensor(0.2280) 2.0 tensor([ 0.3782]) 4.0 tensor([ 0.9447]) 7.0 tensor([ 0.9996])\n",
      "epoch: 450 loss: tensor(0.2267) 2.0 tensor([ 0.3769]) 4.0 tensor([ 0.9453]) 7.0 tensor([ 0.9996])\n",
      "epoch: 455 loss: tensor(0.2255) 2.0 tensor([ 0.3756]) 4.0 tensor([ 0.9460]) 7.0 tensor([ 0.9996])\n",
      "epoch: 460 loss: tensor(0.2242) 2.0 tensor([ 0.3743]) 4.0 tensor([ 0.9466]) 7.0 tensor([ 0.9997])\n",
      "epoch: 465 loss: tensor(0.2230) 2.0 tensor([ 0.3731]) 4.0 tensor([ 0.9472]) 7.0 tensor([ 0.9997])\n",
      "epoch: 470 loss: tensor(0.2218) 2.0 tensor([ 0.3718]) 4.0 tensor([ 0.9478]) 7.0 tensor([ 0.9997])\n",
      "epoch: 475 loss: tensor(0.2206) 2.0 tensor([ 0.3706]) 4.0 tensor([ 0.9484]) 7.0 tensor([ 0.9997])\n",
      "epoch: 480 loss: tensor(0.2194) 2.0 tensor([ 0.3693]) 4.0 tensor([ 0.9490]) 7.0 tensor([ 0.9997])\n",
      "epoch: 485 loss: tensor(0.2183) 2.0 tensor([ 0.3681]) 4.0 tensor([ 0.9496]) 7.0 tensor([ 0.9997])\n",
      "epoch: 490 loss: tensor(0.2171) 2.0 tensor([ 0.3669]) 4.0 tensor([ 0.9501]) 7.0 tensor([ 0.9997])\n",
      "epoch: 495 loss: tensor(0.2160) 2.0 tensor([ 0.3657]) 4.0 tensor([ 0.9507]) 7.0 tensor([ 0.9997])\n"
     ]
    }
   ],
   "source": [
    "loss_=torch.tensor([])\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #for parameter in model.parameters(): print('epoch',epoch,parameter[0]) \n",
    "    y_pred=model(x_data)   #this automtically call forward\n",
    "    loss=criterion(y_pred,y_data)\n",
    "    \n",
    "    \n",
    "    tmp=torch.tensor([loss])\n",
    "    loss_=torch.cat((loss_,tmp))\n",
    "    optimizer.zero_grad()   #initilize gradient to zero before every step, to avoid accumulation ,zero off good for RNN\n",
    "    loss.backward()         #calculate gradient\n",
    "    optimizer.step()        #update parameter (weights)\n",
    "    t0=torch.tensor([2.0])\n",
    "    t1=torch.tensor([4.0])\n",
    "    t2=torch.tensor([7.0])\n",
    "    if(epoch%5==0): print('epoch:',epoch,'loss:',loss,'2.0',model.forward(t0),'4.0',model.forward(t1),'7.0',model.forward(t2))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6053])\n",
      "tensor(-3.6693)\n"
     ]
    }
   ],
   "source": [
    "for i,parameter in enumerate(model.parameters()):\n",
    "    #print('w:',list(model.parameters()[0]),'bias:',list(model.parameters()[0])) \n",
    "\n",
    "    print(parameter[0])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_SGD_1=loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.arange(0,epochs,1),loss_SGD_01.detach().numpy(),label='SGD_0.1')  #lr=0.01 #need to detach gradient for graph breakdown otherwise won't do numpy in the middle of graph (good for end of run)\n",
    "#plt.plot(np.arange(0,epochs,1),loss_SGD_05.detach().numpy(),label='SGD_0.05') \n",
    "#plt.plot(np.arange(0,epochs,1),loss_sgd_mom.detach().numpy(),label='SGD_0.01_mom_0.9')   #lr=0.01 momentum=0.9\n",
    "#plt.plot(np.arange(0,epochs,1),loss_Adam.detach().numpy(),label='Adam_0.1') #lr=0.1\n",
    "#plt.xlim([-1,40])\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "\n",
    "#SGD w/o momentum look better in converging, than with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7825)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=torch.tensor([4.0])\n",
    "model.forward(test).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
