{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('diabetes.csv',header=None,sep=',',dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058823</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.411765</td>\n",
       "      <td>0.165829</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236960</td>\n",
       "      <td>-0.894962</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.647059</td>\n",
       "      <td>-0.216080</td>\n",
       "      <td>-0.180328</td>\n",
       "      <td>-0.353535</td>\n",
       "      <td>-0.791962</td>\n",
       "      <td>-0.076006</td>\n",
       "      <td>-0.854825</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.155779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052161</td>\n",
       "      <td>-0.952178</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.764706</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.931682</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.058823</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.868488</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.294118  0.487437  0.180328 -0.292929  0.000000  0.001490 -0.531170   \n",
       "1 -0.882353 -0.145729  0.081967 -0.414141  0.000000 -0.207153 -0.766866   \n",
       "2 -0.058823  0.839196  0.049180  0.000000  0.000000 -0.305514 -0.492741   \n",
       "3 -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4  0.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "5 -0.411765  0.165829  0.213115  0.000000  0.000000 -0.236960 -0.894962   \n",
       "6 -0.647059 -0.216080 -0.180328 -0.353535 -0.791962 -0.076006 -0.854825   \n",
       "7  0.176471  0.155779  0.000000  0.000000  0.000000  0.052161 -0.952178   \n",
       "8 -0.764706  0.979899  0.147541 -0.090909  0.283688 -0.090909 -0.931682   \n",
       "9 -0.058823  0.256281  0.573770  0.000000  0.000000  0.000000 -0.868488   \n",
       "\n",
       "          7    8  \n",
       "0 -0.033333  0.0  \n",
       "1 -0.666667  1.0  \n",
       "2 -0.633333  0.0  \n",
       "3  0.000000  1.0  \n",
       "4 -0.600000  0.0  \n",
       "5 -0.700000  1.0  \n",
       "6 -0.833333  0.0  \n",
       "7 -0.733333  1.0  \n",
       "8  0.066667  0.0  \n",
       "9  0.100000  0.0  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype='int64')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=Variable(torch.from_numpy(df[[0, 1, 2, 3, 4, 5, 6, 7]].as_matrix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=Variable(torch.from_numpy(df[[8]].as_matrix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([759, 8])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([759, 1])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.fc1=torch.nn.Linear(8,4)   #dropping layers, was close to having 4fc instead of 2, adding layer did not help\n",
    "        self.fc2=torch.nn.Linear(4,1)\n",
    " \n",
    "        #self.sigmoid=torch.nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out1=F.relu(self.fc1(x))\n",
    "        out2=F.sigmoid(self.fc2(out1))\n",
    "\n",
    "        #sof max at end, or sigmoid all the way did not work out\n",
    "        y_pred=out2\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=torch.nn.BCELoss(size_average=True)   #adding weight decay did not help, amsgrad did not help, BCE loss was better than rest\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)  #had to change from SGD to Adam but later noy much difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 / 10000 loss: tensor(0.7042) Accuracy 0.40711462450592883\n",
      "epoch 100 / 10000 loss: tensor(0.6332) Accuracy 0.6561264822134387\n",
      "epoch 200 / 10000 loss: tensor(0.5762) Accuracy 0.6666666666666666\n",
      "epoch 300 / 10000 loss: tensor(0.5241) Accuracy 0.7496706192358367\n",
      "epoch 400 / 10000 loss: tensor(0.4966) Accuracy 0.7707509881422925\n",
      "epoch 500 / 10000 loss: tensor(0.4816) Accuracy 0.764163372859025\n",
      "epoch 600 / 10000 loss: tensor(0.4731) Accuracy 0.769433465085639\n",
      "epoch 700 / 10000 loss: tensor(0.4685) Accuracy 0.7786561264822134\n",
      "epoch 800 / 10000 loss: tensor(0.4661) Accuracy 0.7760210803689065\n",
      "epoch 900 / 10000 loss: tensor(0.4647) Accuracy 0.7760210803689065\n",
      "epoch 1000 / 10000 loss: tensor(0.4638) Accuracy 0.7760210803689065\n",
      "epoch 1100 / 10000 loss: tensor(0.4630) Accuracy 0.7760210803689065\n",
      "epoch 1200 / 10000 loss: tensor(0.4623) Accuracy 0.7747035573122529\n",
      "epoch 1300 / 10000 loss: tensor(0.4617) Accuracy 0.7733860342555995\n",
      "epoch 1400 / 10000 loss: tensor(0.4612) Accuracy 0.7733860342555995\n",
      "epoch 1500 / 10000 loss: tensor(0.4606) Accuracy 0.7720685111989459\n",
      "epoch 1600 / 10000 loss: tensor(0.4602) Accuracy 0.7720685111989459\n",
      "epoch 1700 / 10000 loss: tensor(0.4597) Accuracy 0.7720685111989459\n",
      "epoch 1800 / 10000 loss: tensor(0.4593) Accuracy 0.7720685111989459\n",
      "epoch 1900 / 10000 loss: tensor(0.4588) Accuracy 0.7747035573122529\n",
      "epoch 2000 / 10000 loss: tensor(0.4584) Accuracy 0.7747035573122529\n",
      "epoch 2100 / 10000 loss: tensor(0.4580) Accuracy 0.7733860342555995\n",
      "epoch 2200 / 10000 loss: tensor(0.4577) Accuracy 0.7733860342555995\n",
      "epoch 2300 / 10000 loss: tensor(0.4574) Accuracy 0.7733860342555995\n",
      "epoch 2400 / 10000 loss: tensor(0.4571) Accuracy 0.7733860342555995\n",
      "epoch 2500 / 10000 loss: tensor(0.4569) Accuracy 0.7733860342555995\n",
      "epoch 2600 / 10000 loss: tensor(0.4567) Accuracy 0.7707509881422925\n",
      "epoch 2700 / 10000 loss: tensor(0.4565) Accuracy 0.769433465085639\n",
      "epoch 2800 / 10000 loss: tensor(0.4563) Accuracy 0.7707509881422925\n",
      "epoch 2900 / 10000 loss: tensor(0.4561) Accuracy 0.7707509881422925\n",
      "epoch 3000 / 10000 loss: tensor(0.4560) Accuracy 0.7720685111989459\n",
      "epoch 3100 / 10000 loss: tensor(0.4559) Accuracy 0.7733860342555995\n",
      "epoch 3200 / 10000 loss: tensor(0.4558) Accuracy 0.7733860342555995\n",
      "epoch 3300 / 10000 loss: tensor(0.4556) Accuracy 0.7747035573122529\n",
      "epoch 3400 / 10000 loss: tensor(0.4555) Accuracy 0.7760210803689065\n",
      "epoch 3500 / 10000 loss: tensor(0.4554) Accuracy 0.7760210803689065\n",
      "epoch 3600 / 10000 loss: tensor(0.4553) Accuracy 0.7760210803689065\n",
      "epoch 3700 / 10000 loss: tensor(0.4552) Accuracy 0.7760210803689065\n",
      "epoch 3800 / 10000 loss: tensor(0.4551) Accuracy 0.7760210803689065\n",
      "epoch 3900 / 10000 loss: tensor(0.4550) Accuracy 0.7760210803689065\n",
      "epoch 4000 / 10000 loss: tensor(0.4549) Accuracy 0.7760210803689065\n",
      "epoch 4100 / 10000 loss: tensor(0.4548) Accuracy 0.7760210803689065\n",
      "epoch 4200 / 10000 loss: tensor(0.4548) Accuracy 0.7760210803689065\n",
      "epoch 4300 / 10000 loss: tensor(0.4547) Accuracy 0.7760210803689065\n",
      "epoch 4400 / 10000 loss: tensor(0.4546) Accuracy 0.7760210803689065\n",
      "epoch 4500 / 10000 loss: tensor(0.4545) Accuracy 0.7760210803689065\n",
      "epoch 4600 / 10000 loss: tensor(0.4545) Accuracy 0.7760210803689065\n",
      "epoch 4700 / 10000 loss: tensor(0.4544) Accuracy 0.7760210803689065\n",
      "epoch 4800 / 10000 loss: tensor(0.4543) Accuracy 0.7760210803689065\n",
      "epoch 4900 / 10000 loss: tensor(0.4543) Accuracy 0.7760210803689065\n",
      "epoch 5000 / 10000 loss: tensor(0.4542) Accuracy 0.7760210803689065\n",
      "epoch 5100 / 10000 loss: tensor(0.4540) Accuracy 0.7760210803689065\n",
      "epoch 5200 / 10000 loss: tensor(0.4538) Accuracy 0.7747035573122529\n",
      "epoch 5300 / 10000 loss: tensor(0.4531) Accuracy 0.7747035573122529\n",
      "epoch 5400 / 10000 loss: tensor(0.4522) Accuracy 0.7786561264822134\n",
      "epoch 5500 / 10000 loss: tensor(0.4508) Accuracy 0.7812911725955204\n",
      "epoch 5600 / 10000 loss: tensor(0.4490) Accuracy 0.782608695652174\n",
      "epoch 5700 / 10000 loss: tensor(0.4472) Accuracy 0.7839262187088274\n",
      "epoch 5800 / 10000 loss: tensor(0.4461) Accuracy 0.7839262187088274\n",
      "epoch 5900 / 10000 loss: tensor(0.4450) Accuracy 0.782608695652174\n",
      "epoch 6000 / 10000 loss: tensor(0.4440) Accuracy 0.7812911725955204\n",
      "epoch 6100 / 10000 loss: tensor(0.4426) Accuracy 0.7852437417654808\n",
      "epoch 6200 / 10000 loss: tensor(0.4412) Accuracy 0.782608695652174\n",
      "epoch 6300 / 10000 loss: tensor(0.4392) Accuracy 0.7852437417654808\n",
      "epoch 6400 / 10000 loss: tensor(0.4378) Accuracy 0.7878787878787878\n",
      "epoch 6500 / 10000 loss: tensor(0.4364) Accuracy 0.7878787878787878\n",
      "epoch 6600 / 10000 loss: tensor(0.4352) Accuracy 0.7865612648221344\n",
      "epoch 6700 / 10000 loss: tensor(0.4342) Accuracy 0.7865612648221344\n",
      "epoch 6800 / 10000 loss: tensor(0.4334) Accuracy 0.7865612648221344\n",
      "epoch 6900 / 10000 loss: tensor(0.4328) Accuracy 0.7891963109354414\n",
      "epoch 7000 / 10000 loss: tensor(0.4320) Accuracy 0.7891963109354414\n",
      "epoch 7100 / 10000 loss: tensor(0.4314) Accuracy 0.7865612648221344\n",
      "epoch 7200 / 10000 loss: tensor(0.4304) Accuracy 0.782608695652174\n",
      "epoch 7300 / 10000 loss: tensor(0.4274) Accuracy 0.7786561264822134\n",
      "epoch 7400 / 10000 loss: tensor(0.4264) Accuracy 0.7839262187088274\n",
      "epoch 7500 / 10000 loss: tensor(0.4259) Accuracy 0.7852437417654808\n",
      "epoch 7600 / 10000 loss: tensor(0.4255) Accuracy 0.7878787878787878\n",
      "epoch 7700 / 10000 loss: tensor(0.4247) Accuracy 0.7852437417654808\n",
      "epoch 7800 / 10000 loss: tensor(0.4241) Accuracy 0.7852437417654808\n",
      "epoch 7900 / 10000 loss: tensor(0.4237) Accuracy 0.7878787878787878\n",
      "epoch 8000 / 10000 loss: tensor(0.4235) Accuracy 0.7878787878787878\n",
      "epoch 8100 / 10000 loss: tensor(0.4234) Accuracy 0.7878787878787878\n",
      "epoch 8200 / 10000 loss: tensor(0.4233) Accuracy 0.7878787878787878\n",
      "epoch 8300 / 10000 loss: tensor(0.4232) Accuracy 0.7865612648221344\n",
      "epoch 8400 / 10000 loss: tensor(0.4230) Accuracy 0.7865612648221344\n",
      "epoch 8500 / 10000 loss: tensor(0.4229) Accuracy 0.7865612648221344\n",
      "epoch 8600 / 10000 loss: tensor(0.4227) Accuracy 0.7891963109354414\n",
      "epoch 8700 / 10000 loss: tensor(0.4226) Accuracy 0.7891963109354414\n",
      "epoch 8800 / 10000 loss: tensor(0.4225) Accuracy 0.7905138339920948\n",
      "epoch 8900 / 10000 loss: tensor(0.4224) Accuracy 0.7905138339920948\n",
      "epoch 9000 / 10000 loss: tensor(0.4223) Accuracy 0.7905138339920948\n",
      "epoch 9100 / 10000 loss: tensor(0.4222) Accuracy 0.7905138339920948\n",
      "epoch 9200 / 10000 loss: tensor(0.4222) Accuracy 0.7918313570487484\n",
      "epoch 9300 / 10000 loss: tensor(0.4222) Accuracy 0.7905138339920948\n",
      "epoch 9400 / 10000 loss: tensor(0.4221) Accuracy 0.7905138339920948\n",
      "epoch 9500 / 10000 loss: tensor(0.4221) Accuracy 0.7891963109354414\n",
      "epoch 9600 / 10000 loss: tensor(0.4221) Accuracy 0.7891963109354414\n",
      "epoch 9700 / 10000 loss: tensor(0.4220) Accuracy 0.7891963109354414\n",
      "epoch 9800 / 10000 loss: tensor(0.4220) Accuracy 0.7891963109354414\n",
      "epoch 9900 / 10000 loss: tensor(0.4220) Accuracy 0.7891963109354414\n"
     ]
    }
   ],
   "source": [
    "epochs=10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    y_pred=model(x_data)\n",
    "    loss=criterion(y_pred,y_data)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    y_pred_round=torch.round(y_pred)\n",
    "    #mean_acc=torch.mean(y_data==y_pred_round)\n",
    "    mean_acc=(y_data==y_pred_round).sum().item()/y_data.size()[0]\n",
    "    if (epoch%100==0): print('epoch',epoch,'/',epochs,'loss:',loss,'Accuracy',mean_acc)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5905],\n",
       "        [ 0.6681],\n",
       "        [ 0.5801],\n",
       "        [ 0.6763],\n",
       "        [ 0.5667],\n",
       "        [ 0.6347],\n",
       "        [ 0.6855],\n",
       "        [ 0.6124],\n",
       "        [ 0.5841],\n",
       "        [ 0.5918]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_round[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
