{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets, transforms,utils, models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])   #for pretrained need normalization to imagenet input\n",
    "\n",
    "data_transforms_train = transforms.Compose([transforms.RandomRotation([-30,30]),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "data_transforms_test_eval = transforms.Compose([transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset=datasets.CIFAR10('CIFAR10/',train=True,transform=data_transforms_train,download=True)\n",
    "train_loader=DataLoader(trainset,batch_size=64,shuffle=True) #use all three channels\n",
    "\n",
    "testset=datasets.CIFAR10('CIFAR10/',train=False,transform=data_transforms_test_eval,download=True)\n",
    "test_loader=DataLoader(testset,batch_size=64,shuffle=True)\n",
    "\n",
    "arch='alexnet'\n",
    "node_hidden1=4096\n",
    "node_hidden2=1024\n",
    "node_hidden3=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(arch=='alexnet'):\n",
    "    model = models.alexnet(pretrained=True)\n",
    "    input_size = 9216\n",
    "    hidden_sizes = [node_hidden1,node_hidden2,node_hidden3]\n",
    "    output_size = 10\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "                              ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                              ('relu1', nn.ReLU()),\n",
    "                              ('dropout1',nn.Dropout()),\n",
    "                              ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
    "                              ('relu2', nn.ReLU()),\n",
    "                              ('dropout2',nn.Dropout()),\n",
    "                              ('fc3', nn.Linear(hidden_sizes[1], hidden_sizes[2])),\n",
    "                              ('relu3', nn.ReLU()),\n",
    "                              ('dropout3',nn.Dropout()),        \n",
    "                              ('fc4', nn.Linear(hidden_sizes[2], output_size))\n",
    "#                              ('output', nn.LogSoftmax(dim=1))  will do cross entropy\n",
    "                              ]))\n",
    "\n",
    "    model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AlexNet_mod(nn.Module):\n",
    "\n",
    "#     def __init__(self, num_classes=10):\n",
    "#         super(AlexNet_mod, self).__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#             nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(256 * 6 * 6, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 1000),   # 1000 removed\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(1000, 10),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.view(x.size(0), 256 * 6 * 6)\n",
    "#         x = self.classifier(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "criterion=torch.nn.CrossEntropyLoss()  #if increase the lr to 0.1, it kicks to local min and stays\n",
    "optimizer=torch.optim.SGD(model.classifier.parameters(),lr=0.01,momentum=0.9)  #had to change from SGD to Adam but later noy much difference\n",
    "lr_scheduler_=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "#lr_scheduler_=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(train_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for image,label in iter(train_loader):\n",
    "\n",
    "            #input.resize_(input.size()[0], 784)   take to forward\n",
    "            y_pred=model(image)   #this is 64 (bacth_size)*10\n",
    "\n",
    "            if(count==0): print(y_pred.size(),label.size())\n",
    "            loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "            loss_running=loss_running+loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count=count+1\n",
    "            #y_pred_round=torch.round(y_pred)\n",
    "            count_batch=count_batch+(label.size()[0])\n",
    "            _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "            acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "            sum_acc=sum_acc+acc\n",
    "            if(count%200==0): \n",
    "                print('epoch',epoch+1,'/',epochs,'train running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "                print('-----')\n",
    "                test_function(test_loader)\n",
    "                print('-----')\n",
    "                model.train()\n",
    "\n",
    "        check_loss=(loss_running/count_batch)\n",
    "        lr_scheduler_.step(check_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(test_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "    for input,label in iter(test_loader):\n",
    "        model.eval()\n",
    "\n",
    "        #input.resize_(input.size()[0], 784)   take to forward\n",
    "        y_pred=model(input)   #this is 64 (bacth_size)*10\n",
    "\n",
    "        #if(count==0): print(y_pred.size(),label.size())\n",
    "        loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "        loss_running=loss_running+loss.item()\n",
    "        count=count+1\n",
    "\n",
    "        count_batch=count_batch+(label.size()[0])\n",
    "        _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "        acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "        sum_acc=sum_acc+acc\n",
    "        if(count%100==0): print('test running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test_function(test_loader)   # w/o convnet :result show over fitting on train 64%, but overall 50% on test is not too bad wihtout convnet\n",
    "#w/ convnet just after 5 epoch training the test got to 63% (50% train)\n",
    "#after 10 epoch test get to 66% pretty good without big networks\n",
    "\n",
    "#CiFAR10 with inception better in training improve to 64% but not much better for test at 64% (may be need derop out and more fc)\n",
    "\n",
    "#after more fc on top of inception got to 70% test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "epoch 1 / 10 train running_loss: 0.030190545208752154 Accuracy 26.3203125\n",
      "-----\n",
      "test running_loss: 0.021555963940918445 Accuracy 49.59375\n",
      "-----\n",
      "epoch 1 / 10 train running_loss: 0.02767259328626096 Accuracy 32.546875\n",
      "-----\n",
      "test running_loss: 0.01775102874264121 Accuracy 56.796875\n",
      "-----\n",
      "epoch 1 / 10 train running_loss: 0.02631572445233663 Accuracy 36.265625\n",
      "-----\n",
      "test running_loss: 0.01614627324976027 Accuracy 63.109375\n",
      "-----\n",
      "epoch 2 / 10 train running_loss: 0.025613909860514164 Accuracy 38.48334375977479\n",
      "-----\n",
      "test running_loss: 0.01534952225163579 Accuracy 65.671875\n",
      "-----\n",
      "epoch 2 / 10 train running_loss: 0.02507131890278922 Accuracy 40.10976982737053\n",
      "-----\n",
      "test running_loss: 0.014511408153921365 Accuracy 67.59375\n",
      "-----\n",
      "epoch 2 / 10 train running_loss: 0.024632929191567985 Accuracy 41.514227642276424\n",
      "-----\n",
      "test running_loss: 0.014002577662467956 Accuracy 68.6875\n",
      "-----\n",
      "epoch 2 / 10 train running_loss: 0.024262389510587772 Accuracy 42.56521350723602\n",
      "-----\n",
      "test running_loss: 0.012678648792207241 Accuracy 71.890625\n",
      "-----\n",
      "epoch 3 / 10 train running_loss: 0.02398423292267162 Accuracy 43.487058179543325\n",
      "-----\n",
      "test running_loss: 0.013798842756077647 Accuracy 68.34375\n",
      "-----\n",
      "epoch 3 / 10 train running_loss: 0.02374953996366284 Accuracy 44.21479705309981\n",
      "-----\n",
      "test running_loss: 0.013631342761218548 Accuracy 68.875\n",
      "-----\n",
      "epoch 3 / 10 train running_loss: 0.023513433947312944 Accuracy 44.9110270202652\n",
      "-----\n",
      "test running_loss: 0.011757999216206372 Accuracy 73.640625\n",
      "-----\n",
      "epoch 3 / 10 train running_loss: 0.0233165152342971 Accuracy 45.48484762337958\n",
      "-----\n",
      "test running_loss: 0.012052461714483797 Accuracy 73.109375\n",
      "-----\n",
      "epoch 4 / 10 train running_loss: 0.023150331452108253 Accuracy 45.9942915233031\n",
      "-----\n",
      "test running_loss: 0.01247963055036962 Accuracy 72.0625\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "train_function(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
