{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets,transforms,utils\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])   #needed to do grayscale cob=nversion before normalizing to tensor\n",
    "trainset=datasets.CIFAR10('CIFAR10/',train=True,transform=transform,download=True)\n",
    "train_loader=DataLoader(trainset,batch_size=64,shuffle=True) #use all three channels\n",
    "\n",
    "testset=datasets.CIFAR10('CIFAR10/',train=False,transform=transform,download=True)\n",
    "test_loader=DataLoader(testset,batch_size=64,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2c8673fa710>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image,label=next(iter(train_loader))\n",
    "print(image.size())\n",
    "print(label.size())\n",
    "plt.imshow(image[0][0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  0,  5,  6,  7,  8,  9,  2,  2,  0,  1,  2,  7,  9,\n",
       "         8,  6,  4,  3,  3,  1,  1,  0,  8,  8,  5,  5,  8,  8,\n",
       "         9,  6,  6,  1,  7,  2,  3,  6,  2,  2,  6,  2,  9,  0,\n",
       "         5,  6,  2,  2,  1,  3,  8,  7,  4,  1,  1,  0,  8,  0,\n",
       "         8,  5,  4,  7,  8,  2,  4,  0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inception_(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self,input_):\n",
    "        super(inception_,self).__init__()\n",
    "           \n",
    "        self.conv1_1_1=torch.nn.Conv2d(input_,16,kernel_size=1)\n",
    "        \n",
    "        self.conv1_1_2=torch.nn.Conv2d(input_,16,kernel_size=1)\n",
    "        self.conv5_5_2=torch.nn.Conv2d(16,24,kernel_size=5,padding=2)\n",
    "        \n",
    "        self.conv1_1_3=torch.nn.Conv2d(input_,16,kernel_size=1) \n",
    "        self.conv3_3_1_3=torch.nn.Conv2d(16,24,kernel_size=3,padding=1)\n",
    "        self.conv3_3_2_3=torch.nn.Conv2d(24,24,kernel_size=3,padding=1)\n",
    "        \n",
    "        #self.avgpool4=torch.nn.AvgPool2d(kernel_size=3,stride=1,padding=1)\n",
    "        self.conv1_1_4=torch.nn.Conv2d(input_,24,kernel_size=1)\n",
    "\n",
    "   \n",
    "    def forward(self,x): \n",
    "        \n",
    "        #input_=x.size(0)\n",
    "        #x=x.view(-1)  ?\n",
    "        x1_1=self.conv1_1_1(x)\n",
    "        \n",
    "        x5_5=self.conv1_1_2(x)\n",
    "        x5_5=self.conv5_5_2(x5_5)\n",
    "        \n",
    "        x3_3=self.conv1_1_3(x)\n",
    "        x3_3=self.conv3_3_1_3(x3_3)\n",
    "        x3_3=self.conv3_3_2_3(x3_3)\n",
    "        \n",
    "        xpool=F.avg_pool2d(x,kernel_size=3,stride=1,padding=1)\n",
    "        xpool=self.conv1_1_4(xpool)\n",
    "        \n",
    "        outputs=[x1_1,x5_5,x3_3,xpool]\n",
    "        \n",
    "        return torch.cat(outputs,1)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "        self.conv1=torch.nn.Conv2d(3,10,kernel_size=5)\n",
    "        self.conv2=torch.nn.Conv2d(88,20,kernel_size=5)\n",
    "        \n",
    "        self.incept1=inception_(input_=10)\n",
    "        self.incept2=inception_(input_=20)\n",
    "        \n",
    "        self.mp=torch.nn.MaxPool2d(2)\n",
    "        self.fc=torch.nn.Linear(2200,1000)\n",
    "        self.dropout0=torch.nn.Dropout(p=0.2)\n",
    "        self.fc1=torch.nn.Linear(1000,500)\n",
    "        self.dropout1=torch.nn.Dropout(p=0.2)\n",
    "        self.fc2=torch.nn.Linear(500,200)\n",
    "        self.dropout2=torch.nn.Dropout(p=0.2)\n",
    "        self.fc3=torch.nn.Linear(200,10)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        input_size=x.size(0)\n",
    "        x=F.relu(self.mp(self.conv1(x)))\n",
    "        \n",
    "        x=self.incept1(x)\n",
    "        \n",
    "        x=F.relu(self.mp(self.conv2(x)))\n",
    "        \n",
    "        x=self.incept2(x)\n",
    "        \n",
    "        x=x.view(input_size,-1)\n",
    "        \n",
    "        x=F.relu(self.fc(x))\n",
    "        x=self.dropout0(x)\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.dropout1(x)\n",
    "        x=F.relu(self.fc2(x))  \n",
    "        x=self.dropout2(x)\n",
    "        x=F.relu(self.fc3(x))\n",
    "        y_pred=x     \n",
    "        \n",
    "        return y_pred\n",
    "\n",
    "model=Network()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "criterion=torch.nn.CrossEntropyLoss()  #if increase the lr to 0.1, it kicks to local min and stays\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)  #had to change from SGD to Adam but later noy much difference\n",
    "lr_scheduler_=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "#lr_scheduler_=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "epoch 1 / 10 running_loss: 0.03590712681412697 Accuracy 12.890625\n",
      "epoch 1 / 10 running_loss: 0.03487946182955057 Accuracy 17.62890625\n",
      "epoch 1 / 10 running_loss: 0.0330093618730704 Accuracy 22.450520833333332\n",
      "epoch 2 / 10 running_loss: 0.031199934552395982 Accuracy 26.798561151079138\n",
      "epoch 2 / 10 running_loss: 0.029653906307728673 Accuracy 30.430635476607456\n",
      "epoch 2 / 10 running_loss: 0.028457581181500838 Accuracy 33.333333333333336\n",
      "epoch 2 / 10 running_loss: 0.02739223145176113 Accuracy 36.046096122923\n",
      "epoch 3 / 10 running_loss: 0.026515946818196964 Accuracy 38.25363622145762\n",
      "epoch 3 / 10 running_loss: 0.025680470470135032 Accuracy 40.29225743675285\n",
      "epoch 3 / 10 running_loss: 0.024995402565558225 Accuracy 42.05185138854141\n",
      "epoch 3 / 10 running_loss: 0.024377311453009726 Accuracy 43.632021833068\n",
      "epoch 4 / 10 running_loss: 0.023818034037424073 Accuracy 45.02267751016578\n",
      "epoch 4 / 10 running_loss: 0.023262276126966474 Accuracy 46.389904725243\n",
      "epoch 4 / 10 running_loss: 0.02275425806067689 Accuracy 47.626999374497366\n",
      "epoch 4 / 10 running_loss: 0.02230883567882841 Accuracy 48.711012425986155\n",
      "epoch 5 / 10 running_loss: 0.02189069510719246 Accuracy 49.76149515170472\n",
      "epoch 5 / 10 running_loss: 0.021468425105159464 Accuracy 50.764461289372974\n",
      "epoch 5 / 10 running_loss: 0.021085227038820053 Accuracy 51.69498887962191\n",
      "epoch 5 / 10 running_loss: 0.020736063842327856 Accuracy 52.557528970239666\n",
      "epoch 6 / 10 running_loss: 0.020389362618975018 Accuracy 53.406709415076634\n",
      "epoch 6 / 10 running_loss: 0.020040388275265233 Accuracy 54.22289246350908\n",
      "epoch 6 / 10 running_loss: 0.019727181239153704 Accuracy 54.96481376172875\n",
      "epoch 6 / 10 running_loss: 0.019450784856663763 Accuracy 55.63196899646451\n",
      "epoch 7 / 10 running_loss: 0.019138902210389757 Accuracy 56.386847044103845\n",
      "epoch 7 / 10 running_loss: 0.01884487256823109 Accuracy 57.072615353818435\n",
      "epoch 7 / 10 running_loss: 0.01858518386582156 Accuracy 57.70017322683091\n",
      "epoch 7 / 10 running_loss: 0.018362187835934286 Accuracy 58.23284450004633\n",
      "epoch 8 / 10 running_loss: 0.018110539246963278 Accuracy 58.83836409133563\n",
      "epoch 8 / 10 running_loss: 0.01786098742414073 Accuracy 59.41585055438112\n",
      "epoch 8 / 10 running_loss: 0.01763350586607879 Accuracy 59.943075190791944\n",
      "epoch 8 / 10 running_loss: 0.017426191507603946 Accuracy 60.43045522418177\n",
      "epoch 9 / 10 running_loss: 0.017195266632224537 Accuracy 60.96731310603691\n",
      "epoch 9 / 10 running_loss: 0.016976121471898756 Accuracy 61.48700523202912\n",
      "epoch 9 / 10 running_loss: 0.016773844634909003 Accuracy 61.94758242566971\n",
      "epoch 9 / 10 running_loss: 0.016588668602678262 Accuracy 62.377797040320274\n",
      "epoch 10 / 10 running_loss: 0.016382098342362733 Accuracy 62.86297049317068\n",
      "epoch 10 / 10 running_loss: 0.016183322406021612 Accuracy 63.3111283941433\n",
      "epoch 10 / 10 running_loss: 0.016005098636552834 Accuracy 63.7214796035953\n",
      "epoch 10 / 10 running_loss: 0.01585127442617003 Accuracy 64.08630866454945\n"
     ]
    }
   ],
   "source": [
    "#torch.set_printoptions(precision=2)\n",
    "def train_function(train_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for image,label in iter(train_loader):\n",
    "\n",
    "            #input.resize_(input.size()[0], 784)   take to forward\n",
    "            y_pred=model(image)   #this is 64 (bacth_size)*10\n",
    "\n",
    "            if(count==0): print(y_pred.size(),label.size())\n",
    "            loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "            loss_running=loss_running+loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count=count+1\n",
    "            #y_pred_round=torch.round(y_pred)\n",
    "            count_batch=count_batch+(label.size()[0])\n",
    "            _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "            acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "            sum_acc=sum_acc+acc\n",
    "            if(count%200==0): print('epoch',epoch+1,'/',epochs,'running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "\n",
    "        check_loss=(loss_running/count_batch)\n",
    "        lr_scheduler_.step(check_loss)\n",
    "\n",
    "train_function(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_loss: 0.014409492444247007 Accuracy 70.875\n"
     ]
    }
   ],
   "source": [
    "#torch.set_printoptions(precision=2)\n",
    "def test_function(test_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "    for input,label in iter(test_loader):\n",
    "        model.eval()\n",
    "\n",
    "        #input.resize_(input.size()[0], 784)   take to forward\n",
    "        y_pred=model(input)   #this is 64 (bacth_size)*10\n",
    "\n",
    "        #if(count==0): print(y_pred.size(),label.size())\n",
    "        loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "        loss_running=loss_running+loss.item()\n",
    "        count=count+1\n",
    "\n",
    "        count_batch=count_batch+(label.size()[0])\n",
    "        _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "        acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "        sum_acc=sum_acc+acc\n",
    "        if(count%100==0): print('running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_function(test_loader)   # w/o convnet :result show over fitting on train 64%, but overall 50% on test is not too bad wihtout convnet\n",
    "#w/ convnet just after 5 epoch training the test got to 63% (50% train)\n",
    "#after 10 epoch test get to 66% pretty good without big networks\n",
    "\n",
    "#CiFAR10 with inception better in training improve to 64% but not much better for test at 64% (may be need derop out and more fc)\n",
    "\n",
    "#after more fc on top of inception got to 70% test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
