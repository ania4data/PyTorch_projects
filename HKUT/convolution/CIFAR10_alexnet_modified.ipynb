{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets, transforms,utils, models\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])   #for pretrained need normalization to imagenet input\n",
    "\n",
    "data_transforms_train = transforms.Compose([transforms.RandomRotation([-30,30]),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "data_transforms_test_eval = transforms.Compose([transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset=datasets.CIFAR10('CIFAR10/',train=True,transform=data_transforms_train,download=True)\n",
    "train_loader=DataLoader(trainset,batch_size=64,shuffle=True) #use all three channels\n",
    "\n",
    "testset=datasets.CIFAR10('CIFAR10/',train=False,transform=data_transforms_test_eval,download=True)\n",
    "test_loader=DataLoader(testset,batch_size=64,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet_mod(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet_mod, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 1000),   # 1000 removed\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(1000, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), 256 * 6 * 6)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=AlexNet_mod()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "criterion=torch.nn.CrossEntropyLoss()  #if increase the lr to 0.1, it kicks to local min and stays\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.9)  #had to change from SGD to Adam but later noy much difference\n",
    "lr_scheduler_=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "#lr_scheduler_=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function(train_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for image,label in iter(train_loader):\n",
    "\n",
    "            #input.resize_(input.size()[0], 784)   take to forward\n",
    "            y_pred=model(image)   #this is 64 (bacth_size)*10\n",
    "\n",
    "            if(count==0): print(y_pred.size(),label.size())\n",
    "            loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "            loss_running=loss_running+loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            count=count+1\n",
    "            #y_pred_round=torch.round(y_pred)\n",
    "            count_batch=count_batch+(label.size()[0])\n",
    "            _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "            acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "            sum_acc=sum_acc+acc\n",
    "            if(count%200==0): \n",
    "                print('epoch',epoch+1,'/',epochs,'train running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "                print('-----')\n",
    "                test_function(test_loader)\n",
    "                print('-----')\n",
    "                model.train()\n",
    "\n",
    "        check_loss=(loss_running/count_batch)\n",
    "        lr_scheduler_.step(check_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(test_loader):\n",
    "    loss_running=0\n",
    "    count=0\n",
    "    count_batch=0\n",
    "    sum_acc=0\n",
    "\n",
    "    for input,label in iter(test_loader):\n",
    "        model.eval()\n",
    "\n",
    "        #input.resize_(input.size()[0], 784)   take to forward\n",
    "        y_pred=model(input)   #this is 64 (bacth_size)*10\n",
    "\n",
    "        #if(count==0): print(y_pred.size(),label.size())\n",
    "        loss=criterion(y_pred,label)    #criterion(y_pred,label), crossentropy criterion need long (output of forward) and normal tensor (target)\n",
    "        loss_running=loss_running+loss.item()\n",
    "        count=count+1\n",
    "\n",
    "        count_batch=count_batch+(label.size()[0])\n",
    "        _,y_pred_=torch.max(y_pred,dim=1)    #argmax is the second value returned by torch.max()  ,this collapse dimension to batch size with argmax of probabililty/value (second) item, first one is the value itself \n",
    "\n",
    "        acc=(label==y_pred_).sum().item()    #/label.size()[0]\n",
    "        sum_acc=sum_acc+acc\n",
    "        if(count%100==0): print('test running_loss:',(loss_running/count_batch),'Accuracy',(sum_acc*100/count_batch))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test_function(test_loader)   # w/o convnet :result show over fitting on train 64%, but overall 50% on test is not too bad wihtout convnet\n",
    "#w/ convnet just after 5 epoch training the test got to 63% (50% train)\n",
    "#after 10 epoch test get to 66% pretty good without big networks\n",
    "\n",
    "#CiFAR10 with inception better in training improve to 64% but not much better for test at 64% (may be need derop out and more fc)\n",
    "\n",
    "#after more fc on top of inception got to 70% test, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10]) torch.Size([64])\n",
      "epoch 1 / 10 running_loss: 0.03597911523655057 Accuracy 9.7421875\n",
      "-----\n",
      "running_loss: 0.03593949612230062 Accuracy 10.34375\n",
      "-----\n",
      "epoch 1 / 10 running_loss: 0.03541254848241806 Accuracy 12.234375\n",
      "-----\n",
      "running_loss: 0.03334174577146769 Accuracy 20.484375\n",
      "-----\n",
      "epoch 1 / 10 running_loss: 0.03472945631171266 Accuracy 14.684895833333334\n",
      "-----\n",
      "running_loss: 0.03193771881982684 Accuracy 21.390625\n",
      "-----\n",
      "epoch 2 / 10 running_loss: 0.03409706214591418 Accuracy 16.56044729433844\n",
      "-----\n",
      "running_loss: 0.03064518455415964 Accuracy 26.296875\n",
      "-----\n",
      "epoch 2 / 10 running_loss: 0.03354084934439992 Accuracy 17.93219914936202\n",
      "-----\n",
      "running_loss: 0.028954978715628386 Accuracy 31.28125\n",
      "-----\n",
      "epoch 2 / 10 running_loss: 0.03301867528466948 Accuracy 19.31415468000834\n",
      "-----\n",
      "running_loss: 0.027594261579215528 Accuracy 33.21875\n",
      "-----\n",
      "epoch 2 / 10 running_loss: 0.03253844868120858 Accuracy 20.527738073968198\n",
      "-----\n",
      "running_loss: 0.025902084931731226 Accuracy 36.734375\n",
      "-----\n",
      "epoch 3 / 10 running_loss: 0.0321256524015394 Accuracy 21.57784641851736\n",
      "-----\n",
      "running_loss: 0.026780212372541426 Accuracy 38.15625\n",
      "-----\n",
      "epoch 3 / 10 running_loss: 0.03174148086320701 Accuracy 22.653426466499862\n",
      "-----\n",
      "running_loss: 0.024685554709285497 Accuracy 41.390625\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "train_function(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
